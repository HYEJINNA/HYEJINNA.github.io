<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>내 블로그</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="내 블로그"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="내 블로그"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="내 블로그"><meta property="og:url" content="https://hyejinna.github.io/"><meta property="og:site_name" content="내 블로그"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://hyejinna.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://HYEJINNA.github.io"},"headline":"내 블로그","image":["https://hyejinna.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"내 블로그","logo":{"@type":"ImageObject","url":"https://hyejinna.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="내 블로그" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-14T00:00:00.000Z" title="2022. 7. 14. 오전 9:00:00">2022-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-22T12:01:37.492Z" title="2022. 7. 22. 오후 9:01:37">2022-07-22</time></span><span class="level-item">4 minutes read (About 643 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/14/0220714/">seborn 라이브러리</a></h1><div class="content"><h2 id="Visualizing-statistical-relationships"><a href="#Visualizing-statistical-relationships" class="headerlink" title="Visualizing statistical relationships"></a>Visualizing statistical relationships</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set_theme(style=<span class="string">&quot;darkgrid&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Relating variables with scatter plots</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_4_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>,y=<span class="string">&quot;tip&quot;</span>,hue=<span class="string">&quot;smoker&quot;</span>,data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7efce42f6590&gt;
</code></pre>
<p><img src="/images/0714/output_5_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>,y=<span class="string">&quot;tip&quot;</span>,hue=<span class="string">&quot;smoker&quot;</span>,style=<span class="string">&quot;smoker&quot;</span>,</span><br><span class="line">            data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_6_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>,y=<span class="string">&quot;tip&quot;</span>,hue=<span class="string">&quot;smoker&quot;</span>,style=<span class="string">&quot;time&quot;</span>,data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_7_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, hue=<span class="string">&quot;size&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_8_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, hue=<span class="string">&quot;size&quot;</span>, palette=<span class="string">&quot;ch:r=-.5, l=.75&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_9_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, size=<span class="string">&quot;size&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_10_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>,y=<span class="string">&quot;tip&quot;</span>, size=<span class="string">&quot;size&quot;</span>, sizes=(<span class="number">12</span>,<span class="number">200</span>), data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_11_0.png"></p>
<h2 id="Emphasizing-continuity-with-line-plots"><a href="#Emphasizing-continuity-with-line-plots" class="headerlink" title="Emphasizing continuity with line plots"></a>Emphasizing continuity with line plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(<span class="built_in">dict</span>(time=np.arange(<span class="number">500</span>),</span><br><span class="line">                       value=np.random.randn(<span class="number">500</span>).cumsum()))</span><br><span class="line">g = sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;value&quot;</span>, kind=<span class="string">&quot;line&quot;</span>, data=df)</span><br><span class="line">g.figure.autofmt_xdate()</span><br><span class="line">                </span><br><span class="line">                </span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_13_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(np.random.randn(<span class="number">500</span>,<span class="number">2</span>).cumsum(axis=<span class="number">0</span>), columns=[<span class="string">&quot;x&quot;</span>,<span class="string">&quot;y&quot;</span>])</span><br><span class="line">sns.relplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, sort=<span class="literal">False</span>, kind=<span class="string">&quot;line&quot;</span>, data=df);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_14_0.png"></p>
<h2 id="Aggregation-and-representing-uncertainty"><a href="#Aggregation-and-representing-uncertainty" class="headerlink" title="Aggregation and representing uncertainty"></a>Aggregation and representing uncertainty</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fmri = sns.load_dataset(<span class="string">&quot;fmri&quot;</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_16_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, ci=<span class="literal">None</span>, kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_17_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, kind=<span class="string">&quot;line&quot;</span>, ci=<span class="string">&quot;sd&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_18_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, estimator=<span class="literal">None</span>, kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_19_0.png"></p>
<h2 id="Plotting-subsets-of-data-with-semantic-mappings"><a href="#Plotting-subsets-of-data-with-semantic-mappings" class="headerlink" title="Plotting subsets of data with semantic mappings"></a>Plotting subsets of data with semantic mappings</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;event&quot;</span>, kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_21_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;region&quot;</span>, style=<span class="string">&quot;event&quot;</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_22_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;region&quot;</span>, style=<span class="string">&quot;event&quot;</span>,</span><br><span class="line">            dashes=<span class="literal">False</span>, markers=<span class="literal">True</span>, kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_23_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;event&quot;</span>, style=<span class="string">&quot;event&quot;</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_24_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;region&quot;</span>,</span><br><span class="line">           units=<span class="string">&quot;subject&quot;</span>, estimator=<span class="literal">None</span>,</span><br><span class="line">           kind=<span class="string">&quot;line&quot;</span>, data=fmri.query(<span class="string">&quot;event==&#x27;stim&#x27;&quot;</span>));</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_25_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dots = sns.load_dataset(<span class="string">&quot;dots&quot;</span>).query(<span class="string">&quot;align==&#x27;dots&#x27;&quot;</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;firing_rate&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;coherence&quot;</span>, style=<span class="string">&quot;choice&quot;</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=dots);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_26_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">palette = sns.cubehelix_palette(light=<span class="number">.8</span>, n_colors=<span class="number">6</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;firing_rate&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;coherence&quot;</span>, style=<span class="string">&quot;choice&quot;</span>,</span><br><span class="line">            palette=palette,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=dots);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_27_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> LogNorm</span><br><span class="line">palette = sns.cubehelix_palette(light=<span class="number">.7</span>, n_colors=<span class="number">6</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;firing_rate&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;coherence&quot;</span>, style=<span class="string">&quot;choice&quot;</span>,</span><br><span class="line">            hue_norm=LogNorm(),</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>,</span><br><span class="line">            data=dots.query(<span class="string">&quot;coherence &gt; 0&quot;</span>));</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_28_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;firing_rate&quot;</span>,</span><br><span class="line">            size=<span class="string">&quot;coherence&quot;</span>, style=<span class="string">&quot;choice&quot;</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=dots);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_29_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;firing_rate&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;coherence&quot;</span>, size=<span class="string">&quot;choice&quot;</span>,</span><br><span class="line">            palette=palette,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=dots);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_30_0.png"></p>
<h2 id="Plotting-with-date-data"><a href="#Plotting-with-date-data" class="headerlink" title="Plotting with date data"></a>Plotting with date data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(<span class="built_in">dict</span>(time=pd.date_range(<span class="string">&quot;2017-1-1&quot;</span>, periods=<span class="number">500</span>),</span><br><span class="line">                       value=np.random.randn(<span class="number">500</span>).cumsum()))</span><br><span class="line">g= sns.relplot(x=<span class="string">&quot;time&quot;</span>, y=<span class="string">&quot;value&quot;</span>, kind=<span class="string">&quot;line&quot;</span>, data=df)</span><br><span class="line">g.figure.autofmt_xdate()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_32_0.png"></p>
<h2 id="Showing-multiple-relationships-with-facets"><a href="#Showing-multiple-relationships-with-facets" class="headerlink" title="Showing multiple relationships with facets"></a>Showing multiple relationships with facets</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, hue=<span class="string">&quot;smoker&quot;</span>,</span><br><span class="line">            col=<span class="string">&quot;time&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_34_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;subject&quot;</span>,</span><br><span class="line">            col=<span class="string">&quot;region&quot;</span>, row=<span class="string">&quot;event&quot;</span>, height=<span class="number">3</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, estimator=<span class="literal">None</span>, data=fmri);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_35_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;timepoint&quot;</span>, y=<span class="string">&quot;signal&quot;</span>, hue=<span class="string">&quot;event&quot;</span>, style=<span class="string">&quot;event&quot;</span>,</span><br><span class="line">            col=<span class="string">&quot;subject&quot;</span>, col_wrap=<span class="number">5</span>,</span><br><span class="line">            height=<span class="number">3</span>, aspect=<span class="number">.75</span>, linewidth=<span class="number">2.5</span>,</span><br><span class="line">            kind=<span class="string">&quot;line&quot;</span>, data=fmri.query(<span class="string">&quot;region==&#x27;frontal&#x27;&quot;</span>));</span><br></pre></td></tr></table></figure>


<p><img src="/images/0714/output_36_0.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-07T00:00:00.000Z" title="2022. 7. 7. 오전 9:00:00">2022-07-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-07T11:32:57.643Z" title="2022. 7. 7. 오후 8:32:57">2022-07-07</time></span><span class="level-item">19 minutes read (About 2887 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/07/lecture-in-humanedu/">캐글입문</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here&#x27;s several helpful packages to load</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the read-only &quot;../input/&quot; directory</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; </span></span><br><span class="line"><span class="comment"># You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session</span></span><br></pre></td></tr></table></figure>

<h2 id="라이브러리-불러오기"><a href="#라이브러리-불러오기" class="headerlink" title="라이브러리 불러오기"></a>라이브러리 불러오기</h2><ul>
<li>주요 라이브러리 버전을 확인한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb </span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pandas version :&quot;</span>, pd.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;numpy version :&quot;</span>, np.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;matplotlib version :&quot;</span>, mpl.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;seaborn version :&quot;</span>, sns.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;scikit-learn version :&quot;</span>, sklearn.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;xgboost version :&quot;</span>, xgb.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;lightgbm version :&quot;</span>, lgb.__version__)</span><br></pre></td></tr></table></figure>

<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><ul>
<li>pandas 활용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DATA_PATH = <span class="string">&#x27;/kaggle/input/house-prices-advanced-regression-techniques/&#x27;</span></span><br><span class="line">train = pd.read_csv(DATA_PATH + <span class="string">&quot;train.csv&quot;</span>)</span><br><span class="line">test = pd.read_csv(DATA_PATH + <span class="string">&quot;test.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;데이터 불러오기 완료!&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="데이터-둘러보기"><a href="#데이터-둘러보기" class="headerlink" title="데이터 둘러보기"></a>데이터 둘러보기</h2><ul>
<li>데이터를 둘러봅니다</li>
<li>train : 행갯수 1460 열갯수81 (SalePrice 존재)</li>
<li>test : 행갯수 1459 열갯수 80 (SalePrice 컬럼 미존재)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.shape, test.shape</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.info()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.info()</span><br></pre></td></tr></table></figure>

<h2 id="데이터-시각화"><a href="#데이터-시각화" class="headerlink" title="데이터 시각화"></a>데이터 시각화</h2><ul>
<li><p>여기에서는 생략</p>
</li>
<li><p>종속변수 분포확인필요</p>
</li>
<li><p>샤피로 검정</p>
</li>
<li><p>정규분포인가요?</p>
</li>
</ul>
<ul>
<li>정규분포가 아니면 &gt; 로그변환, 박스코스 변환 등등</li>
<li>정규분포로 만들어줘야한다</li>
</ul>
<ul>
<li>선형모델의 상능을 올리기 위해서</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line">(mu,sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>, mu)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;표준편차:&quot;</span>,sigma)</span><br><span class="line"></span><br><span class="line">fig, ax=plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">sns.histplot(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">ax.<span class="built_in">set</span>(title=<span class="string">&quot;SalePrice Distribution&quot;</span>)</span><br><span class="line">ax.axvline(mu,color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.text(mu+<span class="number">10000</span>,<span class="number">160</span>,<span class="string">&#x27;Mean of SalePrice&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>로그변환을 해서 정규분포로 변환해준다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;SalePrice&#x27;</span>][:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>로그변환을 해서 정규분포로 바꿔준다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 로그 변환</span></span><br><span class="line">train[<span class="string">&#x27;SalePrice&#x27;</span>]= np.log1p(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"></span><br><span class="line">(mu,sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>, mu)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;표준편차:&quot;</span>,sigma)</span><br><span class="line"></span><br><span class="line">fig, ax=plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">sns.histplot(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">ax.<span class="built_in">set</span>(title=<span class="string">&quot;SalePrice Distribution&quot;</span>)</span><br><span class="line">ax.axvline(mu,color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.text(mu+<span class="number">0.0001</span>,<span class="number">160</span>,<span class="string">&#x27;Mean of SalePrice&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">170</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="데이터-전처리"><a href="#데이터-전처리" class="headerlink" title="데이터 전처리"></a>데이터 전처리</h2><ul>
<li>컬럼 갯수가 많을때, 어떤 컬럼을 삭제할지 결정</li>
<li>머신러닝 연산속도부터 높여야 한다</li>
</ul>
<h3 id="데이터-ID값-제거"><a href="#데이터-ID값-제거" class="headerlink" title="데이터 ID값 제거"></a>데이터 ID값 제거</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train [<span class="string">&#x27;Id&#x27;</span>][:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_ID = train[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line">test_ID = test[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line"></span><br><span class="line">train = train.drop([<span class="string">&#x27;Id&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = test.drop([<span class="string">&#x27;Id&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">test.shape</span><br></pre></td></tr></table></figure>

<h3 id="Y값-추출"><a href="#Y값-추출" class="headerlink" title="Y값 추출"></a>Y값 추출</h3><ul>
<li>train데이터에 SalePrice만 따로 저장한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y=train[<span class="string">&#x27;SalePrice&#x27;</span>]</span><br><span class="line">train = train.drop(<span class="string">&#x27;SalePrice&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.shape</span><br></pre></td></tr></table></figure>

<h3 id="데이터-합치기"><a href="#데이터-합치기" class="headerlink" title="데이터 합치기"></a>데이터 합치기</h3><ul>
<li>실전 원칙 : train 따로 정리 &#x2F; test 따로 정리</li>
<li>Data Leakage오류를 범할 가능성이 높다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = pd.concat([train, test]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">all_df.shape</span><br></pre></td></tr></table></figure>

<h2 id="결측치-확인"><a href="#결측치-확인" class="headerlink" title="결측치 확인"></a>결측치 확인</h2><ul>
<li>결측치의 비율 확인하는 사용자 정의 함수 작</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check_na</span>(<span class="params">data, head_num = <span class="number">6</span></span>):</span><br><span class="line">  isnull_na = (data.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(data)) * <span class="number">100</span></span><br><span class="line">  data_na = isnull_na.drop(isnull_na[isnull_na == <span class="number">0</span>].index).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">  missing_data = pd.DataFrame(&#123;<span class="string">&#x27;Missing Ratio&#x27;</span> :data_na, </span><br><span class="line">                               <span class="string">&#x27;Data Type&#x27;</span>: data.dtypes[data_na.index]&#125;)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;결측치 데이터 컬럼과 건수:\n&quot;</span>, missing_data.head(head_num))</span><br><span class="line"></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>결측치 제거</li>
<li>결측치 비율이 높은 변수들을 모두 제거하기로 했다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df = all_df.drop([<span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;MiscFeature&#x27;</span>, <span class="string">&#x27;Alley&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;FireplaceQu&#x27;</span>, <span class="string">&#x27;LotFrontage&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br><span class="line">check_na(all_df)</span><br></pre></td></tr></table></figure>

<h2 id="결측치-채우기"><a href="#결측치-채우기" class="headerlink" title="결측치 채우기"></a>결측치 채우기</h2><ul>
<li>train데이터와 test데이터가 섞이면 안됨</li>
<li>train&#x2F;test 분리해서 진행해야한다</li>
<li>문자데이터: 자주 등장하는 빈도값으로 채움</li>
<li>숫자데이더: 평균이 아니라, 중간값으로 채움</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#all_df[&#x27;BsmtCond&#x27;].value_counts().index[0]</span></span><br><span class="line">all_df[<span class="string">&#x27;BsmtCond&#x27;</span>].mode()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 문자열 데이터만 추출</span></span><br><span class="line">cat_all_vars = train.select_dtypes(exclude=[np.number])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of all_vars&quot;</span>, <span class="built_in">len</span>(<span class="built_in">list</span>(cat_all_vars)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 문자열 데이터 중에서 이미 기 삭제했던 Feature들이 있었기 때문에, </span></span><br><span class="line"><span class="comment"># 한번 더 Feature를 정리하는 코드를 작성한다. </span></span><br><span class="line"><span class="comment"># 따라서 38개의 Feature만 추출했다. </span></span><br><span class="line">final_cat_vars = []</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> cat_all_vars:</span><br><span class="line">    <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;MiscFeature&#x27;</span>, <span class="string">&#x27;Alley&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;FireplaceQu&#x27;</span>]:</span><br><span class="line">        final_cat_vars.append(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of final_cat_vars&quot;</span>, <span class="built_in">len</span>(final_cat_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이제 각 Feature 마다 빈도수가 가장 많이 나타나는 값을 추가하는 코드를 작성한다. </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> final_cat_vars:</span><br><span class="line">  all_df[i] = all_df[i].fillna(all_df[i].mode()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이제 수치형 데이터만 남은 것을 확인한다. </span></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>수치형 데이터의 결측치를 추가할수 있다</li>
<li>이번에는 수치형 데이터만 추출한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 방법은 기존과 동일하다. </span></span><br><span class="line"><span class="comment"># 이번에는 수치형 데이터만 추출한다. </span></span><br><span class="line">num_all_vars = <span class="built_in">list</span>(train.select_dtypes(include=[np.number]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of all_vars&quot;</span>, <span class="built_in">len</span>(num_all_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수치형 데이터 중, 결측치가 많았던 `LotFrontage`만 처리한다. </span></span><br><span class="line">num_all_vars.remove(<span class="string">&#x27;LotFrontage&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of final_cat_vars&quot;</span>, <span class="built_in">len</span>(num_all_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이번에는 수치형 데이터의 평균이 아닌 중간값을 지정했다. </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> num_all_vars:</span><br><span class="line">  all_df[i].fillna(value=all_df[i].median(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_df.info()</span><br></pre></td></tr></table></figure>

<h2 id="도출-변수"><a href="#도출-변수" class="headerlink" title="도출 변수"></a>도출 변수</h2><ul>
<li><p>새로운 도출변수를 작성 (기존 변수 활용)</p>
</li>
<li><p>기존 변수 제거</p>
</li>
<li><p>각 층의 면적으로 모두 더해 전체 면적으러로 계산한 새로운 변수를 작성한다</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;TotalSF&#x27;</span>] = all_df[<span class="string">&#x27;TotalBsmtSF&#x27;</span>] + all_df[<span class="string">&#x27;1stFlrSF&#x27;</span>] + all_df[<span class="string">&#x27;2ndFlrSF&#x27;</span>]</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;TotalBsmtSF&#x27;</span>, <span class="string">&#x27;1stFlrSF&#x27;</span>, <span class="string">&#x27;2ndFlrSF&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;Total_Bathrooms&#x27;</span>] = (all_df[<span class="string">&#x27;FullBath&#x27;</span>] + (<span class="number">0.5</span> * all_df[<span class="string">&#x27;HalfBath&#x27;</span>]) + all_df[<span class="string">&#x27;BsmtFullBath&#x27;</span>] + (<span class="number">0.5</span> * all_df[<span class="string">&#x27;BsmtHalfBath&#x27;</span>]))</span><br><span class="line">all_df[<span class="string">&#x27;Total_porch_sf&#x27;</span>] = (all_df[<span class="string">&#x27;OpenPorchSF&#x27;</span>] + all_df[<span class="string">&#x27;3SsnPorch&#x27;</span>] + all_df[<span class="string">&#x27;EnclosedPorch&#x27;</span>] + all_df[<span class="string">&#x27;ScreenPorch&#x27;</span>])</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;FullBath&#x27;</span>, <span class="string">&#x27;HalfBath&#x27;</span>, <span class="string">&#x27;BsmtFullBath&#x27;</span>, <span class="string">&#x27;BsmtHalfBath&#x27;</span>, <span class="string">&#x27;OpenPorchSF&#x27;</span>, <span class="string">&#x27;3SsnPorch&#x27;</span>, <span class="string">&#x27;EnclosedPorch&#x27;</span>, <span class="string">&#x27;ScreenPorch&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li>연도와 관련된 변수를 추출하는 코드 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">num_all_vars = <span class="built_in">list</span>(train.select_dtypes(include=[np.number]))</span><br><span class="line">year_feature = []</span><br><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> num_all_vars:</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;Yr&#x27;</span> <span class="keyword">in</span> var:</span><br><span class="line">    year_feature.append(var)</span><br><span class="line">  <span class="keyword">elif</span> <span class="string">&#x27;Year&#x27;</span> <span class="keyword">in</span> var:</span><br><span class="line">    year_feature.append(var)</span><br><span class="line">  <span class="keyword">else</span>:  </span><br><span class="line">    <span class="built_in">print</span>(var, <span class="string">&quot;is not related with Year&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(year_feature)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">6</span>), sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i, var <span class="keyword">in</span> <span class="built_in">enumerate</span>(year_feature):</span><br><span class="line">  <span class="keyword">if</span> var != <span class="string">&#x27;YrSold&#x27;</span>:</span><br><span class="line">    ax[i].scatter(train[var], y, alpha=<span class="number">0.3</span>)</span><br><span class="line">    ax[i].set_title(<span class="string">&#x27;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(var), size=<span class="number">15</span>)</span><br><span class="line">    ax[i].set_ylabel(<span class="string">&#x27;SalePrice&#x27;</span>, size=<span class="number">15</span>, labelpad=<span class="number">12.5</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = all_df.drop([<span class="string">&#x27;YearBuilt&#x27;</span>, <span class="string">&#x27;GarageYrBlt&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">YearsSinceRemodel = train[<span class="string">&#x27;YrSold&#x27;</span>].astype(<span class="built_in">int</span>) - train[<span class="string">&#x27;YearRemodAdd&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">ax.scatter(YearsSinceRemodel, y, alpha=<span class="number">0.3</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;YearsSinceRemodel&#x27;</span>] = all_df[<span class="string">&#x27;YrSold&#x27;</span>].astype(<span class="built_in">int</span>) - all_df[<span class="string">&#x27;YearRemodAdd&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;YrSold&#x27;</span>, <span class="string">&#x27;YearRemodAdd&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<h2 id="더미-변수"><a href="#더미-변수" class="headerlink" title="더미 변수"></a>더미 변수</h2><ul>
<li>더미 변수란 독립변수를 0과 1로 변환하는 변수를 말한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>

<ul>
<li>사용자 정의함수 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count_dummy</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>]= all_df[<span class="string">&#x27;PoolArea&#x27;</span>].apply(count_dummy)</span><br><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;GarageArea&#x27;</span>]= all_df[<span class="string">&#x27;GarageArea&#x27;</span>].apply(count_dummy)</span><br><span class="line">all_df[<span class="string">&#x27;GarageArea&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;Fireplaces&#x27;</span>]= all_df[<span class="string">&#x27;Fireplaces&#x27;</span>].apply(count_dummy)</span><br><span class="line">all_df[<span class="string">&#x27;Fireplaces&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_df.info()</span><br></pre></td></tr></table></figure>

<h2 id="Label-Encoding-Ordinal-Enciding-One-Hot-Encoding"><a href="#Label-Encoding-Ordinal-Enciding-One-Hot-Encoding" class="headerlink" title="Label Encoding, Ordinal Enciding, One Hot Encoding"></a>Label Encoding, Ordinal Enciding, One Hot Encoding</h2><ul>
<li>인코딩은 문자 데이터를 수치로 변환하는 방법중의 하나이</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 분류모형</span></span><br><span class="line"><span class="comment"># 종속변수(양성, 음성)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">labels = encoder.transform(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(temp[<span class="string">&#x27;Food_Name&#x27;</span>]), <span class="string">&quot;==&gt;&quot;</span>, labels)</span><br></pre></td></tr></table></figure>

<ul>
<li>Ordinal Encoding은 독립변수에만 사용한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OrdinalEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = OrdinalEncoder()</span><br><span class="line">labels = encoder.fit_transform(temp[[<span class="string">&#x27;Food_Name&#x27;</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(temp[<span class="string">&#x27;Food_Name&#x27;</span>]), <span class="string">&quot;==&gt;&quot;</span>, labels.tolist())</span><br></pre></td></tr></table></figure>

<ul>
<li>Pandas 메서드 통해서 직접 숫자로 변환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">temp[<span class="string">&#x27;Food_No&#x27;</span>] = temp.Food_Name.replace(to_replace = [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], value = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(temp[[<span class="string">&#x27;Food_Name&#x27;</span>, <span class="string">&#x27;Food_No&#x27;</span>]])</span><br></pre></td></tr></table></figure>

<ul>
<li>One Hot Encoding</li>
</ul>
<ul>
<li>sscikit-learn 방식이 조금 복잡하다</li>
<li>그래서 보통은 pandas get_dummies() 함수를 활용한</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = LabelBinarizer()</span><br><span class="line">encoder.fit(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">transformed = encoder.transform(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">ohe_df = pd.DataFrame(transformed)</span><br><span class="line">temp = pd.concat([temp, ohe_df], axis=<span class="number">1</span>).drop([<span class="string">&#x27;Food_Name&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">temp.columns = [<span class="string">&#x27;Calories&#x27;</span>, <span class="string">&#x27;Food_Name_Apple&#x27;</span>, <span class="string">&#x27;Food_Name_Broccoli&#x27;</span>, <span class="string">&#x27;Food_Name_Chicken&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(temp)</span><br><span class="line"><span class="built_in">print</span>(temp.shape)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">temp = pd.get_dummies(temp)</span><br><span class="line"><span class="built_in">print</span>(temp)</span><br><span class="line"><span class="built_in">print</span>(temp.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li>본 데이터에 적용</li>
</ul>
<ul>
<li>여기서는 Ordinal Encoding 적용안한다(단, 실전에서는 꼭 찾아서 해야한다)</li>
</ul>
<ul>
<li>One Hot Encoding 적용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = pd.get_dummies(all_df).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">all_df.shape</span><br></pre></td></tr></table></figure>

<ul>
<li>train, test 데이터 합쳐서 진행</li>
<li>train, test 데이터 재분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = all_df.iloc[:<span class="built_in">len</span>(y), :]</span><br><span class="line">test = all_df.iloc[<span class="built_in">len</span>(y):, :]</span><br><span class="line"></span><br><span class="line">X.shape, y.shape, test.shape</span><br></pre></td></tr></table></figure>

<h2 id="과제"><a href="#과제" class="headerlink" title="과제"></a>과제</h2><ul>
<li>남은 시간동안 교재를 보고 머신러닝 학습 및 RMSE를 구하세요</li>
<li>데이터 셋 분리 </li>
<li>X 데이터를 X_train, X_test, y_train, y_test로 구분</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.3</span>, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>

<h2 id="평가-지표"><a href="#평가-지표" class="headerlink" title="평가 지표"></a>평가 지표</h2><ul>
<li>MAE, MSE, RMSE</li>
</ul>
<h3 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h3><ul>
<li>실제값과 예측값의 차이, 오차, 오차들의 절댓값 평균을 말한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mean_absolute_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + np.<span class="built_in">abs</span>(yt - yp)</span><br><span class="line">        <span class="comment"># 절댓값 오차의 평균</span></span><br><span class="line">    mae = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line">y_true = [<span class="number">400</span>, <span class="number">300</span>, <span class="number">800</span>]</span><br><span class="line">y_pred = [<span class="number">380</span>, <span class="number">320</span>, <span class="number">777</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE:&quot;</span>, mean_absolute_error(y_true, y_pred))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_absolute_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + np.<span class="built_in">abs</span>(yt - yp)</span><br><span class="line">        <span class="comment"># 절댓값 오차의 평균</span></span><br><span class="line">    mae = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_squared_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + (yt - yp) ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># 제곱값 오차의 평균</span></span><br><span class="line">    mse = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> mse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">root_mean_squared_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + (yt - yp) ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># 제곱값 오차의 평균</span></span><br><span class="line">    mse = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 제곱근 추가</span></span><br><span class="line">    rmse = np.<span class="built_in">round</span>(np.sqrt(mse), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line">y_true = [<span class="number">400</span>, <span class="number">300</span>, <span class="number">800</span>]</span><br><span class="line">y_pred = [<span class="number">380</span>, <span class="number">320</span>, <span class="number">777</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE:&quot;</span>, mean_absolute_error(y_true, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSE:&quot;</span>, mean_squared_error(y_true, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;RMSE:&quot;</span>, root_mean_squared_error(y_true, y_pred))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#from sklearn.linear_model import LinearRegression</span></span><br><span class="line"><span class="comment">#lr_model = LinearRegression()</span></span><br><span class="line"><span class="comment">#lr_model.fit(X_train, y_train)</span></span><br><span class="line"><span class="comment">#print(lr_model.score(X_train, y_train))</span></span><br><span class="line"><span class="comment">#print(lr_model.score(X_test, y_test))</span></span><br></pre></td></tr></table></figure>

<h2 id="모형만들기"><a href="#모형만들기" class="headerlink" title="모형만들기"></a>모형만들기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rmse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> no.squre(mean_squre_error(y_true, y_pred))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="머신러닝-모형정의-검증평가"><a href="#머신러닝-모형정의-검증평가" class="headerlink" title="머신러닝 모형정의, 검증평가"></a>머신러닝 모형정의, 검증평가</h2><ul>
<li>교차 검증 함수 만들기</li>
</ul>
<p>참고 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rmse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(mean_squared_error(y_true, y_pred))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 교차 검증</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score </span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형 정의</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cv_rmse</span>(<span class="params">model, n_folds=<span class="number">5</span></span>):</span><br><span class="line">    cv = KFold(n_splits = n_folds, random_state=<span class="number">42</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    rmse_list = np.sqrt(-cross_val_score(model, X, y, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, cv=cv))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE Value List:&#x27;</span>, np.<span class="built_in">round</span>(rmse_list, <span class="number">4</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE mean List:&#x27;</span>, np.<span class="built_in">round</span>(np.mean(rmse_list), <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> rmse_list </span><br><span class="line"></span><br><span class="line">rmse_scores = &#123;&#125; </span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"></span><br><span class="line">score = cv_rmse(lr_model, n_folds=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;linear regression - mean : &#123;:.4f&#125; (std: &#123;:.4f&#125;)&#x27;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br><span class="line"></span><br><span class="line">rmse_scores[<span class="string">&#x27;Linear Regression&#x27;</span>] = (score.mean(), score.std())</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMRegressor</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cv_rmse</span>(<span class="params">model, n_folds=<span class="number">5</span></span>):</span><br><span class="line">    cv = KFold(n_splits=n_folds, random_state=<span class="number">42</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    rmse_list = np.sqrt(-cross_val_score(model, X, y, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, cv=cv))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE value list:&#x27;</span>, np.<span class="built_in">round</span>(rmse_list, <span class="number">4</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE mean value:&#x27;</span>, np.<span class="built_in">round</span>(np.mean(rmse_list), <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> (rmse_list)</span><br><span class="line"></span><br><span class="line">n_folds = <span class="number">5</span></span><br><span class="line">rmse_scores = &#123;&#125;</span><br><span class="line"><span class="comment">#lr_model = LinearRegression()</span></span><br><span class="line">lgb_model = LGBMRegressor()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">score = cv_rmse(lr_model, n_folds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;linear regression - mean: &#123;:.4f&#125; (std: &#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br><span class="line">rmse_scores[<span class="string">&#x27;linear regression&#x27;</span>] = (score.mean(), score.std())</span><br></pre></td></tr></table></figure>

<ul>
<li>제출 방법</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"></span><br><span class="line"><span class="comment"># X = all_df.iloc[:len(y), :]</span></span><br><span class="line"><span class="comment"># X_test = all_df.iloc[len(y):, :]</span></span><br><span class="line"><span class="comment"># X.shape, y.shape, X_test.shape</span></span><br><span class="line"></span><br><span class="line">lr_model_fit = lr_model.fit(X_train, y_train)</span><br><span class="line">final_preds = np.floor(np.expm1(lr_model_fit.predict(test)))</span><br><span class="line"><span class="built_in">print</span>(final_preds)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">submission = pd.read_csv(DATA_PATH + <span class="string">&quot;sample_submission.csv&quot;</span>)</span><br><span class="line">submission.iloc[:,<span class="number">1</span>] = final_preds</span><br><span class="line"><span class="built_in">print</span>(submission.head())</span><br><span class="line">submission.to_csv(<span class="string">&quot;submission.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-06T11:39:54.239Z" title="2022. 7. 6. 오후 8:39:54">2022-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T13:00:58.747Z" title="2022. 7. 6. 오후 10:00:58">2022-07-06</time></span><span class="level-item">34 minutes read (About 5172 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/06/day0706_1200/">XGboost &amp; LightGBM</a></h1><div class="content"><h2 id="XGboost-amp-LightGBM-2016-2017"><a href="#XGboost-amp-LightGBM-2016-2017" class="headerlink" title="XGboost &amp; LightGBM (2016-2017)"></a>XGboost &amp; LightGBM (2016-2017)</h2><ul>
<li>전통적인 머신러닝 알고리즘의 융합</li>
</ul>
<ul>
<li>선형회귀 릿지 라쏘, 과적합 방지 위한 규제</li>
<li>결정트리의 핵심적인 알고리즘</li>
<li>경사하강법</li>
<li>부스팅 기법</li>
</ul>
<ul>
<li>문제점 : 파라미터의 개수가 매우 많음</li>
<li>왜 많이 쓸까요?</li>
</ul>
<ul>
<li>모델학습 속도 </li>
<li>성능 </li>
<li>가장 좋은 모델이란, 학습속도는 빠르면서 성능은 좋은 것(지금까지 나온 알고리즘보다)</li>
</ul>
<ul>
<li>Python</li>
</ul>
<ul>
<li>JAVA, C, C++</li>
<li>C, C++ &#x2F; r data.table 패키지</li>
</ul>
<ul>
<li>큰 회사들 개발</li>
</ul>
<ul>
<li>첫 번째 옵션, 우리가 자체적으로 배포하자-&gt; Pyhthon Wrapper API</li>
<li>R, 머신러닝 프레임워크 종류 다양</li>
<li>파이썬 머신러닝 &#x3D; Scikit-Learn에서 쉽게 쓸 수 있도록 개발, Scikit-Learn</li>
</ul>
<p> 참고 <a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/stable/python/python_intro.html">https://xgboost.readthedocs.io/en/stable/python/python_intro.html</a> </p>
<h1 id="XGboost-Scikit-Learn-API방식-amp-python-Wrapper-방식"><a href="#XGboost-Scikit-Learn-API방식-amp-python-Wrapper-방식" class="headerlink" title="XGboost (Scikit-Learn API방식 &amp; python Wrapper 방식)"></a>XGboost (Scikit-Learn API방식 &amp; python Wrapper 방식)</h1><h3 id="python-Wrapper-방식"><a href="#python-Wrapper-방식" class="headerlink" title="python Wrapper 방식"></a>python Wrapper 방식</h3><ul>
<li>X_train, y_train</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 분리</span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"><span class="comment"># titanic.info()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># X, 독립변수, y 종속변수</span></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, </span><br><span class="line">                                                    y, </span><br><span class="line">                                                    stratify = y, </span><br><span class="line">                                                    test_size = <span class="number">0.3</span>, </span><br><span class="line">                                                    random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((623, 3), (268, 3), (623,), (268,))
</code></pre>
<ul>
<li>여기가 핵심</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dtrain = xgb.DMatrix(data = X_train, label = y_train)</span><br><span class="line">dtest = xgb.DMatrix(data=X_test, label=y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dtrain)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>&lt;xgboost.core.DMatrix object at 0x7fc937b31ad0&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#max_depth = 트리의 깊이</span></span><br><span class="line"><span class="comment">#n_estimator = 트리의 수</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span> : <span class="number">3</span>, </span><br><span class="line">    <span class="string">&#x27;n_estimators&#x27;</span> : <span class="number">100</span>, </span><br><span class="line">    <span class="string">&#x27;eta&#x27;</span> : <span class="number">0.1</span>, </span><br><span class="line">    <span class="string">&#x27;objective&#x27;</span> : <span class="string">&#x27;binary:logistic&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">num_rounds = <span class="number">400</span></span><br><span class="line"></span><br><span class="line">w_list = [(dtrain, <span class="string">&#x27;train&#x27;</span>), (dtest, <span class="string">&#x27;test&#x27;</span>)]</span><br><span class="line">xgb_ml = xgb.train(params = params, </span><br><span class="line">                   dtrain = dtrain, </span><br><span class="line">                   num_boost_round = <span class="number">400</span>, </span><br><span class="line">                   early_stopping_rounds = <span class="number">100</span>, </span><br><span class="line">                   evals = w_list)</span><br></pre></td></tr></table></figure>

<pre><code>[0]	train-error:0.260032	test-error:0.302239
Multiple eval metrics have been passed: &#39;test-error&#39; will be used for early stopping.

Will train until test-error hasn&#39;t improved in 100 rounds.
[1]	train-error:0.260032	test-error:0.302239
[2]	train-error:0.260032	test-error:0.302239
[3]	train-error:0.260032	test-error:0.302239
[4]	train-error:0.260032	test-error:0.302239
[5]	train-error:0.260032	test-error:0.302239
[6]	train-error:0.260032	test-error:0.302239
[7]	train-error:0.260032	test-error:0.302239
[8]	train-error:0.260032	test-error:0.302239
[9]	train-error:0.260032	test-error:0.302239
[10]	train-error:0.260032	test-error:0.302239
[11]	train-error:0.260032	test-error:0.302239
[12]	train-error:0.260032	test-error:0.302239
[13]	train-error:0.247191	test-error:0.298507
[14]	train-error:0.247191	test-error:0.298507
[15]	train-error:0.248796	test-error:0.302239
[16]	train-error:0.248796	test-error:0.302239
[17]	train-error:0.248796	test-error:0.302239
[18]	train-error:0.248796	test-error:0.302239
[19]	train-error:0.248796	test-error:0.302239
[20]	train-error:0.248796	test-error:0.302239
[21]	train-error:0.248796	test-error:0.302239
[22]	train-error:0.248796	test-error:0.302239
[23]	train-error:0.248796	test-error:0.302239
[24]	train-error:0.248796	test-error:0.302239
[25]	train-error:0.248796	test-error:0.302239
[26]	train-error:0.248796	test-error:0.302239
[27]	train-error:0.248796	test-error:0.302239
[28]	train-error:0.247191	test-error:0.302239
[29]	train-error:0.247191	test-error:0.302239
[30]	train-error:0.247191	test-error:0.302239
[31]	train-error:0.243981	test-error:0.298507
[32]	train-error:0.247191	test-error:0.302239
[33]	train-error:0.243981	test-error:0.298507
[34]	train-error:0.243981	test-error:0.298507
[35]	train-error:0.242376	test-error:0.294776
[36]	train-error:0.24077	test-error:0.294776
[37]	train-error:0.24077	test-error:0.294776
[38]	train-error:0.24077	test-error:0.294776
[39]	train-error:0.24077	test-error:0.294776
[40]	train-error:0.24077	test-error:0.294776
[41]	train-error:0.24077	test-error:0.294776
[42]	train-error:0.24077	test-error:0.294776
[43]	train-error:0.24077	test-error:0.294776
[44]	train-error:0.24077	test-error:0.302239
[45]	train-error:0.24077	test-error:0.302239
[46]	train-error:0.24077	test-error:0.302239
[47]	train-error:0.24077	test-error:0.302239
[48]	train-error:0.24077	test-error:0.302239
[49]	train-error:0.24077	test-error:0.302239
[50]	train-error:0.24077	test-error:0.302239
[51]	train-error:0.24077	test-error:0.302239
[52]	train-error:0.23435	test-error:0.302239
[53]	train-error:0.23435	test-error:0.302239
[54]	train-error:0.232745	test-error:0.298507
[55]	train-error:0.229535	test-error:0.298507
[56]	train-error:0.229535	test-error:0.298507
[57]	train-error:0.229535	test-error:0.298507
[58]	train-error:0.229535	test-error:0.298507
[59]	train-error:0.227929	test-error:0.294776
[60]	train-error:0.227929	test-error:0.298507
[61]	train-error:0.227929	test-error:0.298507
[62]	train-error:0.227929	test-error:0.298507
[63]	train-error:0.227929	test-error:0.298507
[64]	train-error:0.227929	test-error:0.298507
[65]	train-error:0.227929	test-error:0.298507
[66]	train-error:0.227929	test-error:0.298507
[67]	train-error:0.227929	test-error:0.298507
[68]	train-error:0.227929	test-error:0.298507
[69]	train-error:0.227929	test-error:0.298507
[70]	train-error:0.227929	test-error:0.298507
[71]	train-error:0.227929	test-error:0.298507
[72]	train-error:0.227929	test-error:0.302239
[73]	train-error:0.227929	test-error:0.302239
[74]	train-error:0.229535	test-error:0.30597
[75]	train-error:0.229535	test-error:0.30597
[76]	train-error:0.229535	test-error:0.30597
[77]	train-error:0.229535	test-error:0.30597
[78]	train-error:0.229535	test-error:0.30597
[79]	train-error:0.229535	test-error:0.30597
[80]	train-error:0.229535	test-error:0.30597
[81]	train-error:0.229535	test-error:0.30597
[82]	train-error:0.229535	test-error:0.30597
[83]	train-error:0.229535	test-error:0.30597
[84]	train-error:0.229535	test-error:0.30597
[85]	train-error:0.229535	test-error:0.30597
[86]	train-error:0.229535	test-error:0.30597
[87]	train-error:0.229535	test-error:0.30597
[88]	train-error:0.229535	test-error:0.30597
[89]	train-error:0.229535	test-error:0.30597
[90]	train-error:0.229535	test-error:0.30597
[91]	train-error:0.229535	test-error:0.30597
[92]	train-error:0.229535	test-error:0.30597
[93]	train-error:0.229535	test-error:0.30597
[94]	train-error:0.227929	test-error:0.313433
[95]	train-error:0.226324	test-error:0.313433
[96]	train-error:0.223114	test-error:0.317164
[97]	train-error:0.223114	test-error:0.317164
[98]	train-error:0.223114	test-error:0.317164
[99]	train-error:0.223114	test-error:0.317164
[100]	train-error:0.223114	test-error:0.317164
[101]	train-error:0.223114	test-error:0.317164
[102]	train-error:0.223114	test-error:0.317164
[103]	train-error:0.223114	test-error:0.317164
[104]	train-error:0.223114	test-error:0.317164
[105]	train-error:0.223114	test-error:0.317164
[106]	train-error:0.223114	test-error:0.317164
[107]	train-error:0.223114	test-error:0.317164
[108]	train-error:0.223114	test-error:0.317164
[109]	train-error:0.223114	test-error:0.317164
[110]	train-error:0.223114	test-error:0.317164
[111]	train-error:0.223114	test-error:0.317164
[112]	train-error:0.223114	test-error:0.317164
[113]	train-error:0.223114	test-error:0.317164
[114]	train-error:0.223114	test-error:0.317164
[115]	train-error:0.223114	test-error:0.317164
[116]	train-error:0.223114	test-error:0.317164
[117]	train-error:0.223114	test-error:0.317164
[118]	train-error:0.223114	test-error:0.317164
[119]	train-error:0.223114	test-error:0.317164
[120]	train-error:0.223114	test-error:0.317164
[121]	train-error:0.223114	test-error:0.317164
[122]	train-error:0.223114	test-error:0.317164
[123]	train-error:0.223114	test-error:0.317164
[124]	train-error:0.224719	test-error:0.317164
[125]	train-error:0.224719	test-error:0.317164
[126]	train-error:0.224719	test-error:0.317164
[127]	train-error:0.221509	test-error:0.317164
[128]	train-error:0.223114	test-error:0.317164
[129]	train-error:0.219904	test-error:0.313433
[130]	train-error:0.215088	test-error:0.313433
[131]	train-error:0.215088	test-error:0.313433
[132]	train-error:0.215088	test-error:0.313433
[133]	train-error:0.215088	test-error:0.313433
[134]	train-error:0.215088	test-error:0.313433
[135]	train-error:0.215088	test-error:0.313433
Stopping. Best iteration:
[35]	train-error:0.242376	test-error:0.294776
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 평가</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">pred_probs = xgb_ml.predict(dtest)</span><br><span class="line">y_pred = [<span class="number">1</span> <span class="keyword">if</span> x&gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.6865671641791045
</code></pre>
<h3 id="Scikit-Learn-API방식"><a href="#Scikit-Learn-API방식" class="headerlink" title="Scikit-Learn API방식"></a>Scikit-Learn API방식</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier <span class="comment"># API </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier()</span></span><br><span class="line">xgb_model = XGBClassifier(objective = <span class="string">&#x27;binary:logistic&#x27;</span>, </span><br><span class="line">                          n_estimators=<span class="number">100</span>, </span><br><span class="line">                          max_depth=<span class="number">3</span>, </span><br><span class="line">                          learning_rate = <span class="number">0.1</span>, </span><br><span class="line">                          num_rounds = <span class="number">400</span>,</span><br><span class="line">                          random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">w_list = [(X_train, y_train), (X_test, y_test)]</span><br><span class="line"></span><br><span class="line">xgb_model.fit(X_train, y_train, eval_set = w_list, eval_metric=<span class="string">&#x27;error&#x27;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_probas = xgb_model.predict_proba(X_test)</span><br><span class="line">y_pred = [<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0]	validation_0-error:0.260032	validation_1-error:0.302239
[1]	validation_0-error:0.260032	validation_1-error:0.302239
[2]	validation_0-error:0.260032	validation_1-error:0.302239
[3]	validation_0-error:0.260032	validation_1-error:0.302239
[4]	validation_0-error:0.260032	validation_1-error:0.302239
[5]	validation_0-error:0.260032	validation_1-error:0.302239
[6]	validation_0-error:0.260032	validation_1-error:0.302239
[7]	validation_0-error:0.260032	validation_1-error:0.302239
[8]	validation_0-error:0.260032	validation_1-error:0.302239
[9]	validation_0-error:0.260032	validation_1-error:0.302239
[10]	validation_0-error:0.260032	validation_1-error:0.302239
[11]	validation_0-error:0.260032	validation_1-error:0.302239
[12]	validation_0-error:0.260032	validation_1-error:0.302239
[13]	validation_0-error:0.247191	validation_1-error:0.298507
[14]	validation_0-error:0.247191	validation_1-error:0.298507
[15]	validation_0-error:0.248796	validation_1-error:0.302239
[16]	validation_0-error:0.248796	validation_1-error:0.302239
[17]	validation_0-error:0.248796	validation_1-error:0.302239
[18]	validation_0-error:0.248796	validation_1-error:0.302239
[19]	validation_0-error:0.248796	validation_1-error:0.302239
[20]	validation_0-error:0.248796	validation_1-error:0.302239
[21]	validation_0-error:0.248796	validation_1-error:0.302239
[22]	validation_0-error:0.248796	validation_1-error:0.302239
[23]	validation_0-error:0.248796	validation_1-error:0.302239
[24]	validation_0-error:0.248796	validation_1-error:0.302239
[25]	validation_0-error:0.248796	validation_1-error:0.302239
[26]	validation_0-error:0.248796	validation_1-error:0.302239
[27]	validation_0-error:0.248796	validation_1-error:0.302239
[28]	validation_0-error:0.247191	validation_1-error:0.302239
[29]	validation_0-error:0.247191	validation_1-error:0.302239
[30]	validation_0-error:0.247191	validation_1-error:0.302239
[31]	validation_0-error:0.243981	validation_1-error:0.298507
[32]	validation_0-error:0.247191	validation_1-error:0.302239
[33]	validation_0-error:0.243981	validation_1-error:0.298507
[34]	validation_0-error:0.243981	validation_1-error:0.298507
[35]	validation_0-error:0.242376	validation_1-error:0.294776
[36]	validation_0-error:0.24077	validation_1-error:0.294776
[37]	validation_0-error:0.24077	validation_1-error:0.294776
[38]	validation_0-error:0.24077	validation_1-error:0.294776
[39]	validation_0-error:0.24077	validation_1-error:0.294776
[40]	validation_0-error:0.24077	validation_1-error:0.294776
[41]	validation_0-error:0.24077	validation_1-error:0.294776
[42]	validation_0-error:0.24077	validation_1-error:0.294776
[43]	validation_0-error:0.24077	validation_1-error:0.294776
[44]	validation_0-error:0.24077	validation_1-error:0.302239
[45]	validation_0-error:0.24077	validation_1-error:0.302239
[46]	validation_0-error:0.24077	validation_1-error:0.302239
[47]	validation_0-error:0.24077	validation_1-error:0.302239
[48]	validation_0-error:0.24077	validation_1-error:0.302239
[49]	validation_0-error:0.24077	validation_1-error:0.302239
[50]	validation_0-error:0.24077	validation_1-error:0.302239
[51]	validation_0-error:0.24077	validation_1-error:0.302239
[52]	validation_0-error:0.23435	validation_1-error:0.302239
[53]	validation_0-error:0.23435	validation_1-error:0.302239
[54]	validation_0-error:0.232745	validation_1-error:0.298507
[55]	validation_0-error:0.229535	validation_1-error:0.298507
[56]	validation_0-error:0.229535	validation_1-error:0.298507
[57]	validation_0-error:0.229535	validation_1-error:0.298507
[58]	validation_0-error:0.229535	validation_1-error:0.298507
[59]	validation_0-error:0.227929	validation_1-error:0.294776
[60]	validation_0-error:0.227929	validation_1-error:0.298507
[61]	validation_0-error:0.227929	validation_1-error:0.298507
[62]	validation_0-error:0.227929	validation_1-error:0.298507
[63]	validation_0-error:0.227929	validation_1-error:0.298507
[64]	validation_0-error:0.227929	validation_1-error:0.298507
[65]	validation_0-error:0.227929	validation_1-error:0.298507
[66]	validation_0-error:0.227929	validation_1-error:0.298507
[67]	validation_0-error:0.227929	validation_1-error:0.298507
[68]	validation_0-error:0.227929	validation_1-error:0.298507
[69]	validation_0-error:0.227929	validation_1-error:0.298507
[70]	validation_0-error:0.227929	validation_1-error:0.298507
[71]	validation_0-error:0.227929	validation_1-error:0.298507
[72]	validation_0-error:0.227929	validation_1-error:0.302239
[73]	validation_0-error:0.227929	validation_1-error:0.302239
[74]	validation_0-error:0.229535	validation_1-error:0.30597
[75]	validation_0-error:0.229535	validation_1-error:0.30597
[76]	validation_0-error:0.229535	validation_1-error:0.30597
[77]	validation_0-error:0.229535	validation_1-error:0.30597
[78]	validation_0-error:0.229535	validation_1-error:0.30597
[79]	validation_0-error:0.229535	validation_1-error:0.30597
[80]	validation_0-error:0.229535	validation_1-error:0.30597
[81]	validation_0-error:0.229535	validation_1-error:0.30597
[82]	validation_0-error:0.229535	validation_1-error:0.30597
[83]	validation_0-error:0.229535	validation_1-error:0.30597
[84]	validation_0-error:0.229535	validation_1-error:0.30597
[85]	validation_0-error:0.229535	validation_1-error:0.30597
[86]	validation_0-error:0.229535	validation_1-error:0.30597
[87]	validation_0-error:0.229535	validation_1-error:0.30597
[88]	validation_0-error:0.229535	validation_1-error:0.30597
[89]	validation_0-error:0.229535	validation_1-error:0.30597
[90]	validation_0-error:0.229535	validation_1-error:0.30597
[91]	validation_0-error:0.229535	validation_1-error:0.30597
[92]	validation_0-error:0.229535	validation_1-error:0.30597
[93]	validation_0-error:0.229535	validation_1-error:0.30597
[94]	validation_0-error:0.227929	validation_1-error:0.313433
[95]	validation_0-error:0.226324	validation_1-error:0.313433
[96]	validation_0-error:0.223114	validation_1-error:0.317164
[97]	validation_0-error:0.223114	validation_1-error:0.317164
[98]	validation_0-error:0.223114	validation_1-error:0.317164
[99]	validation_0-error:0.223114	validation_1-error:0.317164





0.6865671641791045
</code></pre>
<ul>
<li>p275 &#x3D; Scikit-Learn API방식</li>
<li>Scikit-Learn API방식, python Wrapper 방식 비교하기</li>
</ul>
<h1 id="lightGBM-Python-Wrapper-방식-amp-LightGBM-Scikit-Learn-API방식"><a href="#lightGBM-Python-Wrapper-방식-amp-LightGBM-Scikit-Learn-API방식" class="headerlink" title="lightGBM Python Wrapper 방식 &amp; LightGBM Scikit-Learn API방식"></a>lightGBM Python Wrapper 방식 &amp; LightGBM Scikit-Learn API방식</h1><h2 id="lightGBM-Python-Wrapper-방식"><a href="#lightGBM-Python-Wrapper-방식" class="headerlink" title="lightGBM Python Wrapper 방식"></a>lightGBM Python Wrapper 방식</h2><p>참고 <a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">https://lightgbm.readthedocs.io/en/latest/Parameters.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># XGBoost 코드와 유사하다. </span></span><br><span class="line">dtrain = lgb.Dataset(data = X_train, label = y_train)</span><br><span class="line">dtest = lgb.Dataset(data = X_test, label = y_test)</span><br><span class="line"></span><br><span class="line">params = &#123;<span class="string">&#x27;max_depth&#x27;</span>:<span class="number">3</span>,</span><br><span class="line">          <span class="string">&#x27;n_estimators&#x27;</span>:<span class="number">100</span>,</span><br><span class="line">          <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">          <span class="string">&#x27;objective&#x27;</span>:<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;metric&#x27;</span> : <span class="string">&#x27;binary_error&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;num_boost_round&#x27;</span> : <span class="number">400</span>, </span><br><span class="line">          <span class="string">&#x27;verbose&#x27;</span> : <span class="number">1</span>&#125; </span><br><span class="line"></span><br><span class="line">w_list = [dtrain, dtest]</span><br><span class="line">lgb_ml = lgb.train(params=params, train_set = dtrain,\</span><br><span class="line">                  early_stopping_rounds=<span class="number">100</span>, valid_sets= w_list)</span><br><span class="line"></span><br><span class="line">pred_probs = lgb_ml.predict(X_test)</span><br><span class="line">y_pred=[<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
  warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias))


[1]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
Training until validation scores don&#39;t improve for 100 rounds.
[2]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
[3]	training&#39;s binary_error: 0.354735	valid_1&#39;s binary_error: 0.369403
[4]	training&#39;s binary_error: 0.29695	valid_1&#39;s binary_error: 0.354478
[5]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[6]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[7]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[8]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[9]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[10]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.309701
[11]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[12]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[13]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[14]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[15]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[16]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[17]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[18]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[19]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[20]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[21]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[22]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[23]	training&#39;s binary_error: 0.271268	valid_1&#39;s binary_error: 0.313433
[24]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[25]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[26]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[27]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[28]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[29]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[30]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[31]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[32]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[33]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[34]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[35]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[36]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[37]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[38]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[39]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.309701
[40]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[41]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[42]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[43]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[44]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[45]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[46]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[47]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[48]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[49]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[50]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[51]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[52]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[53]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[54]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[55]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[56]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[57]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[58]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[59]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[60]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[61]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[62]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[63]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[64]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[65]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[66]	training&#39;s binary_error: 0.243981	valid_1&#39;s binary_error: 0.309701
[67]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[68]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[69]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[70]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[71]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[72]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[73]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[74]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[75]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[76]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[77]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[78]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[79]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[80]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[81]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[82]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[83]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[84]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[85]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[86]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[87]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[88]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[89]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[90]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[91]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[92]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[93]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[94]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[95]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[96]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[97]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[98]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[99]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[100]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[102]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[103]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[104]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[105]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[106]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.313433
[107]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[108]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[109]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[110]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[111]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[112]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[113]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[114]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[115]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[116]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[117]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[118]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[119]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[120]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[121]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[122]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[123]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[124]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[125]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[126]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[127]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[128]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[129]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[130]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[131]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[132]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[133]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[134]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[135]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[136]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[137]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[138]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[139]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[140]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[141]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[142]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[143]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[144]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.320896
[145]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[146]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[147]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[148]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[149]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[150]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[151]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[152]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[153]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[154]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[155]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[156]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[157]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[158]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[159]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[160]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[161]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[162]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[163]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[164]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[165]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[166]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[167]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[168]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[169]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[170]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[171]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[172]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[173]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[174]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[175]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[176]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[177]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[178]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[179]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[180]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[181]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[182]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[183]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[184]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[185]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[186]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[187]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[188]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[189]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[190]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[191]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[192]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[193]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[194]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[195]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[196]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[197]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[198]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[199]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[200]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[201]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
Early stopping, best iteration is:
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597





0.6940298507462687
</code></pre>
<h2 id="LightGBM-Scikit-Learn-API방식"><a href="#LightGBM-Scikit-Learn-API방식" class="headerlink" title="LightGBM Scikit-Learn API방식"></a>LightGBM Scikit-Learn API방식</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># model </span></span><br><span class="line">w_list = [dtrain, dtest]</span><br><span class="line">model = LGBMClassifier(objective = <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line">                       metric = <span class="string">&#x27;binary_error&#x27;</span>,</span><br><span class="line">                       n_estimators=<span class="number">100</span>, </span><br><span class="line">                       learning_rate=<span class="number">0.1</span>, </span><br><span class="line">                       max_depth=<span class="number">3</span>, </span><br><span class="line">                       num_boost_round = <span class="number">400</span>,</span><br><span class="line">                       random_state = <span class="number">32</span>)</span><br><span class="line">model.fit(X_train, </span><br><span class="line">          y_train, </span><br><span class="line">          eval_set = [(X_train, y_train), (X_test, y_test)], </span><br><span class="line">          verbose=<span class="number">1</span>,</span><br><span class="line">          early_stopping_rounds = <span class="number">100</span>)</span><br><span class="line">y_probas = model.predict_proba(X_test) </span><br><span class="line">y_pred=[<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> y_probas[:, <span class="number">1</span>]] <span class="comment"># 예측 라벨(0과 1로 예측)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
  warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias))


[1]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
Training until validation scores don&#39;t improve for 100 rounds.
[2]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
[3]	training&#39;s binary_error: 0.354735	valid_1&#39;s binary_error: 0.369403
[4]	training&#39;s binary_error: 0.29695	valid_1&#39;s binary_error: 0.354478
[5]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[6]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[7]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[8]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[9]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[10]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.309701
[11]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[12]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[13]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[14]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[15]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[16]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[17]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[18]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[19]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[20]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[21]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[22]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[23]	training&#39;s binary_error: 0.271268	valid_1&#39;s binary_error: 0.313433
[24]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[25]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[26]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[27]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[28]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[29]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[30]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[31]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[32]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[33]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[34]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[35]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[36]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[37]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[38]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[39]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.309701
[40]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[41]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[42]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[43]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[44]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[45]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[46]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[47]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[48]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[49]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[50]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[51]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[52]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[53]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[54]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[55]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[56]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[57]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[58]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[59]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[60]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[61]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[62]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[63]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[64]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[65]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[66]	training&#39;s binary_error: 0.243981	valid_1&#39;s binary_error: 0.309701
[67]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[68]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[69]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[70]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[71]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[72]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[73]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[74]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[75]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[76]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[77]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[78]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[79]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[80]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[81]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[82]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[83]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[84]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[85]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[86]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[87]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[88]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[89]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[90]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[91]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[92]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[93]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[94]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[95]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[96]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[97]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[98]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[99]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[100]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[102]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[103]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[104]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[105]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[106]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.313433
[107]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[108]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[109]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[110]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[111]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[112]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[113]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[114]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[115]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[116]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[117]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[118]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[119]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[120]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[121]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[122]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[123]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[124]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[125]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[126]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[127]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[128]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[129]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[130]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[131]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[132]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[133]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[134]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[135]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[136]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[137]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[138]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[139]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[140]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[141]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[142]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[143]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[144]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.320896
[145]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[146]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[147]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[148]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[149]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[150]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[151]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[152]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[153]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[154]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[155]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[156]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[157]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[158]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[159]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[160]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[161]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[162]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[163]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[164]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[165]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[166]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[167]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[168]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[169]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[170]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[171]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[172]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[173]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[174]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[175]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[176]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[177]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[178]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[179]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[180]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[181]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[182]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[183]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[184]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[185]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[186]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[187]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[188]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[189]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[190]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[191]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[192]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[193]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[194]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[195]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[196]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[197]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[198]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[199]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[200]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[201]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
Early stopping, best iteration is:
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597





0.6940298507462687
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-06T03:00:00.000Z" title="2022. 7. 6. 오후 12:00:00">2022-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:31:33.344Z" title="2022. 7. 6. 오후 12:31:33">2022-07-06</time></span><span class="level-item">a few seconds read (About 86 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/06/test/">test from labtop</a></h1><div class="content"><h2 id="CSV-파일-불러오기"><a href="#CSV-파일-불러오기" class="headerlink" title="CSV 파일 불러오기"></a>CSV 파일 불러오기</h2><ul>
<li>CSV 파일을 불러옵니다</li>
</ul>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mpg1 <span class="operator">&lt;-</span> read.csv<span class="punctuation">(</span><span class="string">&quot;mpg1.csv&quot;</span><span class="punctuation">)</span></span><br><span class="line">str<span class="punctuation">(</span>mpg1<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## &#x27;data.frame&#x27;:	234 obs. of  5 variables:</span><br><span class="line">##  $ manufacturer: chr  &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...</span><br><span class="line">##  $ trans       : chr  &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...</span><br><span class="line">##  $ drv         : chr  &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...</span><br><span class="line">##  $ cty         : int  18 21 20 21 16 18 18 18 16 20 ...</span><br><span class="line">##  $ hwy         : int  29 29 31 30 26 26 27 26 25 28 ...</span><br></pre></td></tr></table></figure>


<h2 id="데이터-시각화하기"><a href="#데이터-시각화하기" class="headerlink" title="데이터 시각화하기"></a>데이터 시각화하기</h2><ul>
<li>cty, hwy 산점도를 그려본다</li>
</ul>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>ggplot2<span class="punctuation">)</span></span><br><span class="line">ggplot<span class="punctuation">(</span>mpg1<span class="punctuation">,</span>aes<span class="punctuation">(</span>x<span class="operator">=</span>cty<span class="punctuation">,</span> y<span class="operator">=</span>hwy<span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">+</span>geom_point<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/rmd_0620/unnamed-chunk-2-1.png"><!-- --></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-06T00:00:00.000Z" title="2022. 7. 6. 오전 9:00:00">2022-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T11:35:32.942Z" title="2022. 7. 6. 오후 8:35:32">2022-07-06</time></span><span class="level-item">25 minutes read (About 3758 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/06/day0706_seborn/">seaborn</a></h1><div class="content"><h2 id="데이터-분석-머신러닝-딥러닝-프로세스"><a href="#데이터-분석-머신러닝-딥러닝-프로세스" class="headerlink" title="데이터 분석(머신러닝, 딥러닝) 프로세스"></a>데이터 분석(머신러닝, 딥러닝) 프로세스</h2><ul>
<li>데이터 불러오기</li>
</ul>
<ul>
<li>CSV, 오라클, MySQL, PostgreSQL, 클라우드DB<br>연동</li>
</ul>
<ul>
<li>탐색적 자료분석</li>
</ul>
<ul>
<li>데이터 전처리 및 가공</li>
</ul>
<ul>
<li>잠정적인 컬럼의 갯수를 지정</li>
<li>머신러닝 모델 (&#x3D;통계모델링, t.test, 분산분석, 교차분석)</li>
<li>머신러닝 모델의 경우 배포(현재는 다루지 않음)</li>
</ul>
<ul>
<li>JSP- 스프링 웹개발시, 배우게 됨</li>
</ul>
<ul>
<li>통계 모델링 경우, p-value값 기준으로, 귀무가설 및 대립가설 검정</li>
<li>(공통) 결과 보고서를 작성하기</li>
</ul>
<ul>
<li>PPT 만들기</li>
</ul>
<h2 id="그래프-복습"><a href="#그래프-복습" class="headerlink" title="그래프 복습"></a>그래프 복습</h2><ul>
<li>수치형 데이터 시각화</li>
<li>범주형 데이터 시각화</li>
<li>데이터 관계 시각화</li>
<li>matplotlib 라이브러리 방법(복잡)</li>
<li>seaborn 라이브러리 방법(단순)</li>
</ul>
<ul>
<li>복잡한 그래프그릴때 -&gt; marplotlib</li>
<li>1줄 그래프 -&gt; seaborn</li>
</ul>
<h2 id="수치형-데이터-시각화"><a href="#수치형-데이터-시각화" class="headerlink" title="수치형 데이터 시각화"></a>수치형 데이터 시각화</h2><ul>
<li>Python의 Seaborn 패키지에는 다양한 내장데이터가 있다</li>
<li>연습용으로 활용가능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line">titanic.head()</span><br></pre></td></tr></table></figure>





  <div id="df-a367cd23-1a74-4500-8c60-d518e7c7e004">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a367cd23-1a74-4500-8c60-d518e7c7e004')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-a367cd23-1a74-4500-8c60-d518e7c7e004 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-a367cd23-1a74-4500-8c60-d518e7c7e004&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 히스토그램</span></span><br><span class="line">sns.histplot(data = titanic, x = <span class="string">&#x27;age&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9d7e7810&gt;
</code></pre>
<p><img src="/images/0706/output_4_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.histplot(data = titanic, x = <span class="string">&#x27;age&#x27;</span>, bins=<span class="number">10</span>, hue=<span class="string">&#x27;alive&#x27;</span>, multiple=<span class="string">&#x27;stack&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9b211150&gt;
</code></pre>
<p><img src="/images/0706/output_5_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 커넬 밀도 추정 함수 그래프</span></span><br><span class="line"><span class="comment"># 연속형 데이터 1개만 쓸때 사용</span></span><br><span class="line">sns.kdeplot(data=titanic, x=<span class="string">&#x27;age&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9b9600d0&gt;
</code></pre>
<p><img src="/images/0706/output_6_1.png"></p>
<ul>
<li>위 그래프 설명….</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.kdeplot(data=titanic, x=<span class="string">&#x27;age&#x27;</span>, hue=<span class="string">&#x27;alive&#x27;</span>, multiple=<span class="string">&#x27;stack&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9b11d9d0&gt;
</code></pre>
<p><img src="/images/0706/output_8_1.png"></p>
<h2 id="분포도"><a href="#분포도" class="headerlink" title="분포도"></a>분포도</h2><ul>
<li>수치형 데이터 한개 컬럼의 분포를 나타내는 그래프 </li>
<li>정규분포인가?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data=titanic, x=<span class="string">&#x27;age&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7f1e9b33de90&gt;
</code></pre>
<p><img src="/images/0706/output_10_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data=titanic, x=<span class="string">&#x27;age&#x27;</span>, kind=<span class="string">&#x27;kde&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7f1e96754710&gt;
</code></pre>
<p><img src="/images/0706/output_11_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data=titanic, x=<span class="string">&#x27;age&#x27;</span>, kde= <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7f1e96754c50&gt;
</code></pre>
<p><img src="/images/0706/output_12_1.png"></p>
<h2 id="범주형-데이터-시각화"><a href="#범주형-데이터-시각화" class="headerlink" title="범주형 데이터 시각화"></a>범주형 데이터 시각화</h2><ul>
<li>x축 범주형, y축 수치데이터</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 막대 그래프</span></span><br><span class="line">sns.barplot(x=<span class="string">&#x27;class&#x27;</span>, y=<span class="string">&#x27;fare&#x27;</span>,data=titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e96626090&gt;
</code></pre>
<p><img src="/images/0706/output_14_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 포인트 플롯</span></span><br><span class="line">sns.pointplot(x=<span class="string">&#x27;class&#x27;</span>, y=<span class="string">&#x27;fare&#x27;</span>, data=titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e965c11d0&gt;
</code></pre>
<p><img src="/images/0706/output_15_1.png"></p>
<ul>
<li>박스플롯</li>
<li>제 1사분위 : 전체 데이터 중 하위 25%</li>
<li>사분위 범위 수(IQR) : 제 3사분위 - 제 1사분위</li>
<li>최댓값 : 제 3사분위 + (1.5 * IQ)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># boxplot</span></span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;class&#x27;</span>, y=<span class="string">&#x27;age&#x27;</span>,data=titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9652f0d0&gt;
</code></pre>
<p><img src="/images/0706/output_17_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 바이올린 플롯</span></span><br><span class="line">sns.violinplot(x = <span class="string">&#x27;class&#x27;</span>, y = <span class="string">&#x27;age&#x27;</span>, hue = <span class="string">&#x27;sex&#x27;</span>, data = titanic, split = <span class="literal">True</span>);</span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_18_0.png"></p>
<h2 id="카운트-플롯"><a href="#카운트-플롯" class="headerlink" title="카운트 플롯"></a>카운트 플롯</h2><ul>
<li>범주형 데이터의 갯수 확인 할때 사용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(x = <span class="string">&#x27;alive&#x27;</span>, data = titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e99086bd0&gt;
</code></pre>
<p><img src="/images/0706/output_20_1.png"></p>
<h2 id="데이터-관계-시각화"><a href="#데이터-관계-시각화" class="headerlink" title="데이터 관계 시각화"></a>데이터 관계 시각화</h2><ul>
<li>여러 데이터 사이의 관계도 파악을 위한 그래프</li>
</ul>
<h3 id="히트맵"><a href="#히트맵" class="headerlink" title="히트맵"></a>히트맵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flights = sns.load_dataset(<span class="string">&#x27;flights&#x27;</span>)</span><br><span class="line">flights.head()</span><br></pre></td></tr></table></figure>





  <div id="df-a2cd537f-318f-4ef7-8db3-e31a3ce65580">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>passengers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1949</td>
      <td>Jan</td>
      <td>112</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1949</td>
      <td>Feb</td>
      <td>118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1949</td>
      <td>Mar</td>
      <td>132</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1949</td>
      <td>Apr</td>
      <td>129</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1949</td>
      <td>May</td>
      <td>121</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a2cd537f-318f-4ef7-8db3-e31a3ce65580')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-a2cd537f-318f-4ef7-8db3-e31a3ce65580 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-a2cd537f-318f-4ef7-8db3-e31a3ce65580&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>판다스에서 복사해서 응용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;foo&#x27;</span>: [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;two&#x27;</span>,</span><br><span class="line">                           <span class="string">&#x27;two&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;bar&#x27;</span>: [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;baz&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">                   <span class="string">&#x27;zoo&#x27;</span>: [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;t&#x27;</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>





  <div id="df-1ae0e23d-eda2-4670-a77a-bee362132409">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>foo</th>
      <th>bar</th>
      <th>baz</th>
      <th>zoo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>one</td>
      <td>A</td>
      <td>1</td>
      <td>x</td>
    </tr>
    <tr>
      <th>1</th>
      <td>one</td>
      <td>B</td>
      <td>2</td>
      <td>y</td>
    </tr>
    <tr>
      <th>2</th>
      <td>one</td>
      <td>C</td>
      <td>3</td>
      <td>z</td>
    </tr>
    <tr>
      <th>3</th>
      <td>two</td>
      <td>A</td>
      <td>4</td>
      <td>q</td>
    </tr>
    <tr>
      <th>4</th>
      <td>two</td>
      <td>B</td>
      <td>5</td>
      <td>w</td>
    </tr>
    <tr>
      <th>5</th>
      <td>two</td>
      <td>C</td>
      <td>6</td>
      <td>t</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1ae0e23d-eda2-4670-a77a-bee362132409')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-1ae0e23d-eda2-4670-a77a-bee362132409 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-1ae0e23d-eda2-4670-a77a-bee362132409&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.pivot(index = <span class="string">&#x27;foo&#x27;</span>, columns = <span class="string">&#x27;bar&#x27;</span>, values = <span class="string">&#x27;baz&#x27;</span>)</span><br></pre></td></tr></table></figure>





  <div id="df-7a884986-8779-41bf-88f8-aa6b83e185b2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>bar</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
    <tr>
      <th>foo</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>one</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>two</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7a884986-8779-41bf-88f8-aa6b83e185b2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-7a884986-8779-41bf-88f8-aa6b83e185b2 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-7a884986-8779-41bf-88f8-aa6b83e185b2&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flights</span><br></pre></td></tr></table></figure>





  <div id="df-2b67b019-ba04-455e-9938-7eb965a94136">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>passengers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1949</td>
      <td>Jan</td>
      <td>112</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1949</td>
      <td>Feb</td>
      <td>118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1949</td>
      <td>Mar</td>
      <td>132</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1949</td>
      <td>Apr</td>
      <td>129</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1949</td>
      <td>May</td>
      <td>121</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>139</th>
      <td>1960</td>
      <td>Aug</td>
      <td>606</td>
    </tr>
    <tr>
      <th>140</th>
      <td>1960</td>
      <td>Sep</td>
      <td>508</td>
    </tr>
    <tr>
      <th>141</th>
      <td>1960</td>
      <td>Oct</td>
      <td>461</td>
    </tr>
    <tr>
      <th>142</th>
      <td>1960</td>
      <td>Nov</td>
      <td>390</td>
    </tr>
    <tr>
      <th>143</th>
      <td>1960</td>
      <td>Dec</td>
      <td>432</td>
    </tr>
  </tbody>
</table>
<p>144 rows × 3 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2b67b019-ba04-455e-9938-7eb965a94136')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-2b67b019-ba04-455e-9938-7eb965a94136 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-2b67b019-ba04-455e-9938-7eb965a94136&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flights[&#x27;year&#x27;].value_counts()</span></span><br><span class="line">flights_pivot = flights.pivot(index = <span class="string">&#x27;month&#x27;</span>, columns = <span class="string">&#x27;year&#x27;</span>, values = <span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line">flights_pivot</span><br></pre></td></tr></table></figure>





  <div id="df-63cc829c-9ecb-46d1-8b3f-826eb006276d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>1949</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>1959</th>
      <th>1960</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Jan</th>
      <td>112</td>
      <td>115</td>
      <td>145</td>
      <td>171</td>
      <td>196</td>
      <td>204</td>
      <td>242</td>
      <td>284</td>
      <td>315</td>
      <td>340</td>
      <td>360</td>
      <td>417</td>
    </tr>
    <tr>
      <th>Feb</th>
      <td>118</td>
      <td>126</td>
      <td>150</td>
      <td>180</td>
      <td>196</td>
      <td>188</td>
      <td>233</td>
      <td>277</td>
      <td>301</td>
      <td>318</td>
      <td>342</td>
      <td>391</td>
    </tr>
    <tr>
      <th>Mar</th>
      <td>132</td>
      <td>141</td>
      <td>178</td>
      <td>193</td>
      <td>236</td>
      <td>235</td>
      <td>267</td>
      <td>317</td>
      <td>356</td>
      <td>362</td>
      <td>406</td>
      <td>419</td>
    </tr>
    <tr>
      <th>Apr</th>
      <td>129</td>
      <td>135</td>
      <td>163</td>
      <td>181</td>
      <td>235</td>
      <td>227</td>
      <td>269</td>
      <td>313</td>
      <td>348</td>
      <td>348</td>
      <td>396</td>
      <td>461</td>
    </tr>
    <tr>
      <th>May</th>
      <td>121</td>
      <td>125</td>
      <td>172</td>
      <td>183</td>
      <td>229</td>
      <td>234</td>
      <td>270</td>
      <td>318</td>
      <td>355</td>
      <td>363</td>
      <td>420</td>
      <td>472</td>
    </tr>
    <tr>
      <th>Jun</th>
      <td>135</td>
      <td>149</td>
      <td>178</td>
      <td>218</td>
      <td>243</td>
      <td>264</td>
      <td>315</td>
      <td>374</td>
      <td>422</td>
      <td>435</td>
      <td>472</td>
      <td>535</td>
    </tr>
    <tr>
      <th>Jul</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>230</td>
      <td>264</td>
      <td>302</td>
      <td>364</td>
      <td>413</td>
      <td>465</td>
      <td>491</td>
      <td>548</td>
      <td>622</td>
    </tr>
    <tr>
      <th>Aug</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>242</td>
      <td>272</td>
      <td>293</td>
      <td>347</td>
      <td>405</td>
      <td>467</td>
      <td>505</td>
      <td>559</td>
      <td>606</td>
    </tr>
    <tr>
      <th>Sep</th>
      <td>136</td>
      <td>158</td>
      <td>184</td>
      <td>209</td>
      <td>237</td>
      <td>259</td>
      <td>312</td>
      <td>355</td>
      <td>404</td>
      <td>404</td>
      <td>463</td>
      <td>508</td>
    </tr>
    <tr>
      <th>Oct</th>
      <td>119</td>
      <td>133</td>
      <td>162</td>
      <td>191</td>
      <td>211</td>
      <td>229</td>
      <td>274</td>
      <td>306</td>
      <td>347</td>
      <td>359</td>
      <td>407</td>
      <td>461</td>
    </tr>
    <tr>
      <th>Nov</th>
      <td>104</td>
      <td>114</td>
      <td>146</td>
      <td>172</td>
      <td>180</td>
      <td>203</td>
      <td>237</td>
      <td>271</td>
      <td>305</td>
      <td>310</td>
      <td>362</td>
      <td>390</td>
    </tr>
    <tr>
      <th>Dec</th>
      <td>118</td>
      <td>140</td>
      <td>166</td>
      <td>194</td>
      <td>201</td>
      <td>229</td>
      <td>278</td>
      <td>306</td>
      <td>336</td>
      <td>337</td>
      <td>405</td>
      <td>432</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-63cc829c-9ecb-46d1-8b3f-826eb006276d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-63cc829c-9ecb-46d1-8b3f-826eb006276d button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-63cc829c-9ecb-46d1-8b3f-826eb006276d&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 위 테이블의 시각화</span></span><br><span class="line">sns.heatmap(data = flights_pivot)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9b2f7dd0&gt;
</code></pre>
<p><img src="/images/0706/output_29_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라인 플롯</span></span><br><span class="line">sns.lineplot(x=<span class="string">&#x27;year&#x27;</span>, y=<span class="string">&#x27;passengers&#x27;</span>,data=flights)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e95f3ae90&gt;
</code></pre>
<p><img src="/images/0706/output_30_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 산점도 </span></span><br><span class="line">tips = sns.load_dataset(<span class="string">&#x27;tips&#x27;</span>)</span><br><span class="line">tips.head()</span><br></pre></td></tr></table></figure>





  <div id="df-82fb9526-10b7-4b8c-a4f9-7172c364d5da">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>sex</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-82fb9526-10b7-4b8c-a4f9-7172c364d5da')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-82fb9526-10b7-4b8c-a4f9-7172c364d5da button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-82fb9526-10b7-4b8c-a4f9-7172c364d5da&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0706/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0706/output.renderimages/0706/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>두 개의 연속형 데이터</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e96293d90&gt;
</code></pre>
<p><img src="/images/0706/output_33_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, hue=<span class="string">&#x27;time&#x27;</span>,data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e96257c10&gt;
</code></pre>
<p><img src="/images/0706/output_34_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, hue=<span class="string">&#x27;sex&#x27;</span>,data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e961f1150&gt;
</code></pre>
<p><img src="/images/0706/output_35_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 회귀선</span></span><br><span class="line">sns.regplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e9675e650&gt;
</code></pre>
<p><img src="/images/0706/output_36_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 머신러닝 리뷰</span></span><br><span class="line">- 가장 인기있는 모델</span><br><span class="line"> + LightGBM, XGboost</span><br></pre></td></tr></table></figure>

<h2 id="선형회귀"><a href="#선형회귀" class="headerlink" title="선형회귀"></a>선형회귀</h2><ul>
<li>선형 회귀식을 찾는 것이 중요</li>
<li>y&#x3D;3x+4에 근사한 데이터 50개 생성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 시드값 고정</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">intercept = <span class="number">4</span> <span class="comment">#절편, 상수</span></span><br><span class="line">slope = <span class="number">3</span> <span class="comment"># 기울기</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 변동성 주기위해 노이즈 생성</span></span><br><span class="line">noise = np.random.randn(<span class="number">50</span>,<span class="number">1</span>)</span><br><span class="line">x=<span class="number">5</span> * np.random.rand(<span class="number">50</span>,<span class="number">1</span>) <span class="comment">#0과 5사이의 실숫값을 50개 생성</span></span><br><span class="line">y=slope*x+intercept+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 프레임 생성</span></span><br><span class="line">data = pd.DataFrame(&#123;<span class="string">&#x27;X&#x27;</span> : x[:, <span class="number">0</span>], <span class="string">&#x27;Y&#x27;</span> : y[:, <span class="number">0</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>

<pre><code>           X          Y
0   0.794848   8.148596
1   0.551876   6.055784
2   3.281648  14.823682
3   0.690915   8.313637
4   0.982912   8.816293
5   1.843626   8.553600
6   4.104966  17.264987
7   0.485506   5.305162
8   4.189725  16.465955
9   0.480492   5.852075
10  4.882297  18.790936
11  2.343256  12.484042
12  4.883805  19.412454
13  3.024228  13.194358
14  3.696318  15.532817
15  0.195939   4.921491
16  1.414035   9.736184
17  0.600983   5.597790
18  1.480701   8.755171
19  0.593639   4.926820
20  1.589916   6.216758
21  2.071315  10.867564
22  0.320737   5.826649
23  3.462361  13.644917
24  2.833007  14.768776
25  1.326947   6.526477
26  2.616240  11.894479
27  0.469703   5.221924
28  2.879732  14.171977
29  4.646481  19.408802
30  1.592845   8.933482
31  3.337052  14.389318
32  0.658989   5.089182
33  3.581636  12.764112
34  1.447030   7.993179
35  0.915957   6.904219
36  2.932565  14.027985
37  0.100538   5.503993
38  4.144700  16.046774
39  0.023477   3.768129
40  3.389083  13.118695
41  1.350040   6.630102
42  3.675970  13.321640
43  4.810943  20.383604
44  1.243766   7.221645
45  2.880787  12.204286
46  2.960210  11.627834
47  2.861260  13.361269
48  1.115408   5.732327
49  4.763745  18.078495
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(data[<span class="string">&#x27;X&#x27;</span>], data[<span class="string">&#x27;Y&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_40_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line">sns.scatterplot(x = <span class="string">&#x27;X&#x27;</span>, y = <span class="string">&#x27;Y&#x27;</span>, data = data)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1e95e82410&gt;
</code></pre>
<p><img src="/images/0706/output_41_1.png"></p>
<h2 id="선형-회귀-모형-훈련"><a href="#선형-회귀-모형-훈련" class="headerlink" title="선형 회귀 모형 훈련"></a>선형 회귀 모형 훈련</h2><ul>
<li>모형 생성 후, 회귀계수 3과 y절편 4에 근사한 값이 나와야 한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y절편:&#x27;</span>, lr_model.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;회귀절편계수:&#x27;</span>, lr_model.coef_)</span><br></pre></td></tr></table></figure>

<pre><code>y절편: [4.05757639]
회귀절편계수: [[3.03754061]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측값</span></span><br><span class="line">y_pred = lr_model.predict(x)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x, y)</span><br><span class="line">ax.plot(x, y_pred, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slope, intercept </span></span><br><span class="line">label = <span class="string">&#x27;slope: &#123;&#125;\nintercept: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>(lr_model.coef_[<span class="number">0</span>][<span class="number">0</span>], <span class="number">2</span>), <span class="built_in">round</span>(lr_model.intercept_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line">ax.text(<span class="number">3.5</span>, <span class="number">4</span>, label, style =<span class="string">&#x27;italic&#x27;</span>, </span><br><span class="line">        fontsize = <span class="number">10</span>, color =<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_44_0.png"></p>
<h2 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">arr, scale=<span class="number">1</span></span>):</span><br><span class="line">    arr = np.asarray(arr)</span><br><span class="line">    result = <span class="number">1</span>/(<span class="number">1</span> + np.exp(-arr*scale))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, y)</span><br><span class="line">ax.grid(which=<span class="string">&#x27;major&#x27;</span>, axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.axvline(x=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ax.set_yticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0.5</span>])</span><br><span class="line">ax.text(<span class="number">0</span>-<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="string">&#x27;0.5&#x27;</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Sigmoid Graph&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_46_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라이브러리 불러오기</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 가져오기</span></span><br><span class="line">x = np.arange(<span class="number">10</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 생성 및 학습</span></span><br><span class="line">model = LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>, C=<span class="number">10.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">model.fit(x, y)</span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression(C=10.0, random_state=0, solver=&#39;liblinear&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모형 평가</span></span><br><span class="line">p_pred = model.predict_proba(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p_perd&#x27;</span>, p_pred, sep=<span class="string">&#x27;Wn&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>p_perdWn[[0.97979027 0.02020973]
 [0.94958202 0.05041798]
 [0.87976149 0.12023851]
 [0.73975066 0.26024934]
 [0.52477284 0.47522716]
 [0.30020373 0.69979627]
 [0.1428487  0.8571513 ]
 [0.06080627 0.93919373]
 [0.02453462 0.97546538]
 [0.00967652 0.99032348]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred&#x27;</span>,y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>y_pred [0 0 0 0 0 1 1 1 1 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x, y)</span><br><span class="line">ax.plot(x, p_pred[:, <span class="number">1</span>], color = <span class="string">&#x27;black&#x27;</span>,  marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.plot()</span><br><span class="line"></span><br><span class="line">ax.set_xticks(x)</span><br><span class="line">ax.set_yticks(np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">ax.grid(which=<span class="string">&#x27;major&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_50_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf_m = confusion_matrix(y, y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_m)</span><br></pre></td></tr></table></figure>

<pre><code>[[5 0]
 [0 5]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cm = confusion_matrix(y, y_pred)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">ax.imshow(cm, cmap = <span class="string">&#x27;Pastel2&#x27;</span>)</span><br><span class="line">ax.grid(<span class="literal">False</span>)</span><br><span class="line">ax.xaxis.<span class="built_in">set</span>(ticks=(<span class="number">0</span>, <span class="number">1</span>), ticklabels=(<span class="string">&#x27;Predicted 0&#x27;</span>, <span class="string">&#x27;Predicted 1&#x27;</span>))</span><br><span class="line">ax.yaxis.<span class="built_in">set</span>(ticks=(<span class="number">0</span>, <span class="number">1</span>), ticklabels=(<span class="string">&#x27;Actual 0&#x27;</span>, <span class="string">&#x27;Actual 1&#x27;</span>))</span><br><span class="line">ax.set_ylim(<span class="number">1.5</span>, -<span class="number">0.5</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        ax.text(j, i, cm[i, j], ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;center&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0706/output_52_0.png"></p>
<p><a target="_blank" rel="noopener" href="https://matplotlib.org/stable/tutorials/colors/colormaps.htm">https://matplotlib.org/stable/tutorials/colors/colormaps.htm</a> 색상참고</p>
<h2 id="결정트리"><a href="#결정트리" class="headerlink" title="결정트리"></a>결정트리</h2><ul>
<li>분류와 회귀 문제에 모두 사용가능</li>
</ul>
<h3 id="주요-개념"><a href="#주요-개념" class="headerlink" title="주요 개념"></a>주요 개념</h3><ul>
<li>작동 원리<ul>
<li>데이터를 가장 잘 구분하는 조건을 정함</li>
<li>조건을 기준으로 데이터를 두 범주로 나눔</li>
<li>나뉜 각 범주의 데이터를 구분하는 조건을 정함</li>
<li>각 조건을 기준으로 데이터를 두 범주로 나눔</li>
<li>언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함</li>
</ul>
</li>
<li>불순도(Impurity)<ul>
<li>한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄</li>
<li>흰색과 검은색이 50:50으로 섞여 있다 (불순도 최대)</li>
<li>흰색과 검은색으로 완전 분리 되었다 (불순도 최소)</li>
</ul>
</li>
<li>엔트로피(Entropy)<ul>
<li>불확실한 정도를 의미함( 0 - 1로 정함)</li>
<li>흰색과 검은색이 50:50으로 섞여 있다_ 엔트로피 1</li>
<li>흰색과 검은색으로 완전 분리 되었다_ 엔트로피 0</li>
</ul>
</li>
<li>정보이득(Information Gain)<ul>
<li>1에서 엔트로피를 뺀 수치</li>
<li>정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함</li>
</ul>
</li>
<li>지니 불순도(Gini Impurity)<ul>
<li>지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line">titanic.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 15 columns):
 #   Column       Non-Null Count  Dtype   
---  ------       --------------  -----   
 0   survived     891 non-null    int64   
 1   pclass       891 non-null    int64   
 2   sex          891 non-null    object  
 3   age          714 non-null    float64 
 4   sibsp        891 non-null    int64   
 5   parch        891 non-null    int64   
 6   fare         891 non-null    float64 
 7   embarked     889 non-null    object  
 8   class        891 non-null    category
 9   who          891 non-null    object  
 10  adult_male   891 non-null    bool    
 11  deck         203 non-null    category
 12  embark_town  889 non-null    object  
 13  alive        891 non-null    object  
 14  alone        891 non-null    bool    
dtypes: bool(2), category(2), float64(2), int64(4), object(5)
memory usage: 80.7+ KB
</code></pre>
<ul>
<li>survived의 비율을 구한다</li>
</ul>
<ul>
<li>0 : 사망자</li>
<li>1 : 생존자</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titanic[<span class="string">&#x27;survived&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>0    549
1    342
Name: survived, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 추출</span></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((623, 3), (268, 3), (623,), (268,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tree_model = DecisionTreeClassifier()</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">acc = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;모형 정확도 : <span class="subst">&#123;acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>) <span class="comment"># 정확도 측정</span></span><br></pre></td></tr></table></figure>

<pre><code>모형 정확도 : 0.675
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 랜덤포레스트</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 훈련</span></span><br><span class="line">rf_model = RandomForestClassifier(random_state=<span class="number">42</span>) <span class="comment"># 랜덤 포레스트 정의</span></span><br><span class="line">rf_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">acc = rf_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;모형 정확도 : <span class="subst">&#123;acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>) <span class="comment"># 정확도 측정</span></span><br></pre></td></tr></table></figure>

<pre><code>모형 정확도 : 0.675
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-05T00:00:00.000Z" title="2022. 7. 5. 오전 9:00:00">2022-07-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:28:35.861Z" title="2022. 7. 6. 오후 12:28:35">2022-07-06</time></span><span class="level-item">an hour read (About 6835 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/05/PyCaret_Sample/">PyCaret</a></h1><div class="content"><ul>
<li>PyCaret 설치</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!pip uninstall sklearn -y</span><br><span class="line">!pip install --upgrade sklearn</span><br><span class="line">!pip install scikit-learn==<span class="number">0.23</span><span class="number">.2</span> --user</span><br><span class="line">!pip install pycaret</span><br><span class="line">!pip install markupsafe==<span class="number">2.0</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>

<pre><code>Found existing installation: sklearn 0.0
Uninstalling sklearn-0.0:
  Successfully uninstalled sklearn-0.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting sklearn
  Downloading sklearn-0.0.tar.gz (1.1 kB)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;sklearn) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;sklearn) (3.1.0)
Requirement already satisfied: numpy&gt;=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;sklearn) (1.21.6)
Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;sklearn) (1.4.1)
Building wheels for collected packages: sklearn
  Building wheel for sklearn (setup.py) ... [?25l[?25hdone
  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=5566fc096d6ec95daf803ef331a5510fa75a651d8e4d1d9f06b99dfd8c4e2161
  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e
Successfully built sklearn
Installing collected packages: sklearn
Successfully installed sklearn-0.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting scikit-learn==0.23.2
  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)
[K     |████████████████████████████████| 6.8 MB 5.6 MB/s 
[?25hRequirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (3.1.0)
Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.21.6)
Requirement already satisfied: scipy&gt;=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.4.1)
Installing collected packages: scikit-learn
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
yellowbrick 1.4 requires scikit-learn&gt;=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.
imbalanced-learn 0.8.1 requires scikit-learn&gt;=0.24, but you have scikit-learn 0.23.2 which is incompatible.[0m
Successfully installed scikit-learn-0.23.2
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pycaret
  Downloading pycaret-2.3.10-py3-none-any.whl (320 kB)
[K     |████████████████████████████████| 320 kB 5.4 MB/s 
[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)
Collecting umap-learn
  Downloading umap-learn-0.5.3.tar.gz (88 kB)
[K     |████████████████████████████████| 88 kB 6.5 MB/s 
[?25hRequirement already satisfied: plotly&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)
Requirement already satisfied: scikit-learn==0.23.2 in /root/.local/lib/python3.7/site-packages (from pycaret) (0.23.2)
Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)
Requirement already satisfied: pyyaml&lt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.13)
Collecting scikit-plot
  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)
Requirement already satisfied: scipy&lt;=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4.1)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.0)
Requirement already satisfied: cufflinks&gt;=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)
Collecting imbalanced-learn==0.7.0
  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)
[K     |████████████████████████████████| 167 kB 50.4 MB/s 
[?25hRequirement already satisfied: gensim&lt;4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)
Collecting kmodes&gt;=0.10.1
  Downloading kmodes-0.12.1-py2.py3-none-any.whl (20 kB)
Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)
Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)
Collecting pyLDAvis
  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)
[K     |████████████████████████████████| 1.7 MB 20.1 MB/s 
[?25h  Installing build dependencies ... [?25l[?25hdone
  Getting requirements to build wheel ... [?25l[?25hdone
  Installing backend dependencies ... [?25l[?25hdone
    Preparing wheel metadata ... [?25l[?25hdone
Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.7)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.5)
Collecting mlflow
  Downloading mlflow-1.27.0-py3-none-any.whl (17.9 MB)
[K     |████████████████████████████████| 17.9 MB 511 kB/s 
[?25hRequirement already satisfied: numba&lt;0.55 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.51.2)
Collecting spacy&lt;2.4.0
  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)
[K     |████████████████████████████████| 10.4 MB 38.8 MB/s 
[?25hRequirement already satisfied: yellowbrick&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4)
Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.7.0)
Collecting pyod
  Downloading pyod-1.0.2.tar.gz (122 kB)
[K     |████████████████████████████████| 122 kB 48.7 MB/s 
[?25hCollecting pandas-profiling&gt;=2.8.0
  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)
[K     |████████████████████████████████| 262 kB 50.6 MB/s 
[?25hCollecting lightgbm&gt;=2.3.1
  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)
[K     |████████████████████████████████| 2.0 MB 52.5 MB/s 
[?25hCollecting Boruta
  Downloading Boruta-0.3-py3-none-any.whl (56 kB)
[K     |████████████████████████████████| 56 kB 4.2 MB/s 
[?25hCollecting mlxtend&gt;=0.17.0
  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)
[K     |████████████████████████████████| 1.3 MB 48.2 MB/s 
[?25hRequirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.7.0-&gt;pycaret) (1.21.6)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2-&gt;pycaret) (3.1.0)
Requirement already satisfied: colorlover&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks&gt;=0.17.0-&gt;pycaret) (0.3.0)
Requirement already satisfied: setuptools&gt;=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks&gt;=0.17.0-&gt;pycaret) (57.4.0)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks&gt;=0.17.0-&gt;pycaret) (1.15.0)
Requirement already satisfied: smart-open&gt;=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim&lt;4.0.0-&gt;pycaret) (5.2.1)
Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (4.4.2)
Requirement already satisfied: prompt-toolkit&lt;2.0.0,&gt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (1.0.18)
Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (2.6.1)
Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (4.8.0)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (0.7.5)
Requirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (5.1.1)
Requirement already satisfied: simplegeneric&gt;0.8 in /usr/local/lib/python3.7/dist-packages (from IPython-&gt;pycaret) (0.8.1)
Requirement already satisfied: jupyterlab-widgets&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&gt;pycaret) (1.1.0)
Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&gt;pycaret) (3.6.0)
Requirement already satisfied: nbformat&gt;=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&gt;pycaret) (5.4.0)
Requirement already satisfied: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&gt;pycaret) (4.10.1)
Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&gt;pycaret) (0.2.0)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets-&gt;pycaret) (5.3.5)
Requirement already satisfied: tornado&gt;=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets-&gt;pycaret) (5.1.1)
Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm&gt;=2.3.1-&gt;pycaret) (0.37.1)
  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)
[K     |████████████████████████████████| 1.3 MB 37.7 MB/s 
[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;pycaret) (3.0.9)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;pycaret) (0.11.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;pycaret) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;pycaret) (1.4.3)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;pycaret) (4.1.1)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (2.15.3)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (4.10.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (0.18.1)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (21.4.0)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (5.7.1)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (4.11.4)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=2.6-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets-&gt;pycaret) (3.8.0)
Requirement already satisfied: llvmlite&lt;0.35,&gt;=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba&lt;0.55-&gt;pycaret) (0.34.0)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;pycaret) (2022.1)
Requirement already satisfied: missingno&gt;=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling&gt;=2.8.0-&gt;pycaret) (0.5.1)
Requirement already satisfied: tqdm&gt;=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling&gt;=2.8.0-&gt;pycaret) (4.64.0)
Collecting visions[type_image_path]==0.7.4
  Downloading visions-0.7.4-py3-none-any.whl (102 kB)
[K     |████████████████████████████████| 102 kB 10.2 MB/s 
[?25hCollecting htmlmin&gt;=0.1.12
  Downloading htmlmin-0.1.12.tar.gz (19 kB)
Collecting multimethod&gt;=1.4
  Downloading multimethod-1.8-py3-none-any.whl (9.8 kB)
Requirement already satisfied: jinja2&gt;=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling&gt;=2.8.0-&gt;pycaret) (2.11.3)
Collecting requests&gt;=2.24.0
  Downloading requests-2.28.1-py3-none-any.whl (62 kB)
[K     |████████████████████████████████| 62 kB 1.3 MB/s 
[?25hCollecting phik&gt;=0.11.1
  Downloading phik-0.12.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (690 kB)
[K     |████████████████████████████████| 690 kB 46.7 MB/s 
[?25hCollecting tangled-up-in-unicode==0.2.0
  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)
[K     |████████████████████████████████| 4.7 MB 42.8 MB/s 
[?25hRequirement already satisfied: pydantic&gt;=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling&gt;=2.8.0-&gt;pycaret) (1.8.2)
Collecting markupsafe~=2.1.1
  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Collecting pyyaml&lt;6.0.0
  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)
[K     |████████████████████████████████| 636 kB 48.3 MB/s 
[?25hRequirement already satisfied: networkx&gt;=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (2.6.3)
Collecting imagehash
  Downloading ImageHash-4.2.1.tar.gz (812 kB)
[K     |████████████████████████████████| 812 kB 53.9 MB/s 
[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (7.1.2)
Collecting scipy&lt;=1.5.4
  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)
[K     |████████████████████████████████| 25.9 MB 55.2 MB/s 
[?25hRequirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly&gt;=4.4.1-&gt;pycaret) (8.0.1)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;IPython-&gt;pycaret) (0.2.5)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (2022.6.15)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (2.10)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;2.4.0-&gt;pycaret) (0.7.7)
Collecting plac&lt;1.2.0,&gt;=0.9.6
  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)
Collecting thinc&lt;7.5.0,&gt;=7.4.1
  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)
[K     |████████████████████████████████| 1.0 MB 44.5 MB/s 
[?25hRequirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;2.4.0-&gt;pycaret) (0.9.1)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;2.4.0-&gt;pycaret) (2.0.6)
Collecting catalogue&lt;1.1.0,&gt;=0.0.7
  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)
Collecting srsly&lt;1.1.0,&gt;=1.0.2
  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)
[K     |████████████████████████████████| 184 kB 48.8 MB/s 
[?25hRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;2.4.0-&gt;pycaret) (3.0.6)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;2.4.0-&gt;pycaret) (1.0.7)
Requirement already satisfied: notebook&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (5.3.1)
Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (5.6.1)
Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (1.8.0)
Requirement already satisfied: terminado&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.13.3)
Requirement already satisfied: pyzmq&gt;=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets-&gt;pycaret) (23.1.0)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&gt;=0.8.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.7.0)
Collecting yellowbrick&gt;=1.0.1
  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)
[K     |████████████████████████████████| 271 kB 51.0 MB/s 
[?25hCollecting numpy&gt;=1.13.3
  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)
[K     |████████████████████████████████| 14.8 MB 41.8 MB/s 
[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash-&gt;visions[type_image_path]==0.7.4-&gt;pandas-profiling&gt;=2.8.0-&gt;pycaret) (1.3.0)
Collecting querystring-parser
  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)
Collecting prometheus-flask-exporter
  Downloading prometheus_flask_exporter-0.20.2-py3-none-any.whl (18 kB)
Requirement already satisfied: click&gt;=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (7.1.2)
Collecting databricks-cli&gt;=0.8.7
  Downloading databricks-cli-0.17.0.tar.gz (81 kB)
[K     |████████████████████████████████| 81 kB 7.6 MB/s 
[?25hRequirement already satisfied: sqlparse&gt;=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (0.4.2)
Collecting docker&gt;=4.0.0
  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)
[K     |████████████████████████████████| 146 kB 46.0 MB/s 
[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (0.4)
Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (1.1.4)
Requirement already satisfied: sqlalchemy&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (1.4.37)
Requirement already satisfied: protobuf&gt;=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (3.17.3)
Collecting gunicorn
  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)
[K     |████████████████████████████████| 79 kB 7.5 MB/s 
[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (21.3)
Collecting alembic
  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)
[K     |████████████████████████████████| 209 kB 47.5 MB/s 
[?25hCollecting gitpython&gt;=2.1.0
  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)
[K     |████████████████████████████████| 181 kB 47.2 MB/s 
[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow-&gt;pycaret) (1.3.0)
Collecting pyjwt&gt;=1.7.0
  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)
Requirement already satisfied: oauthlib&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow-&gt;pycaret) (3.2.0)
Requirement already satisfied: tabulate&gt;=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow-&gt;pycaret) (0.8.9)
Collecting websocket-client&gt;=0.32.0
  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)
[K     |████████████████████████████████| 54 kB 2.4 MB/s 
[?25hCollecting gitdb&lt;5,&gt;=4.0.1
  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)
[K     |████████████████████████████████| 63 kB 1.6 MB/s 
[?25hCollecting smmap&lt;6,&gt;=3.0.1
  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)
Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy&gt;=1.4.0-&gt;mlflow-&gt;pycaret) (1.1.2)
Collecting Mako
  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)
[K     |████████████████████████████████| 78 kB 7.2 MB/s 
[?25hRequirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask-&gt;mlflow-&gt;pycaret) (1.0.1)
Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask-&gt;mlflow-&gt;pycaret) (1.1.0)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.7.1)
Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.6.0)
Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (5.0.0)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (1.5.0)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.8.4)
Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets-&gt;pycaret) (0.5.1)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk-&gt;pycaret) (2022.6.2)
Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter-&gt;mlflow-&gt;pycaret) (0.14.1)
Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis-&gt;pycaret) (0.16.0)
Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis-&gt;pycaret) (2.8.1)
Collecting funcy
  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)
Collecting pyLDAvis
  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)
[K     |████████████████████████████████| 1.7 MB 44.8 MB/s 
[?25h  Installing build dependencies ... [?25l[?25hdone
  Getting requirements to build wheel ... [?25l[?25hdone
  Installing backend dependencies ... [?25l[?25hdone
    Preparing wheel metadata ... [?25l[?25hdone
  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)
[K     |████████████████████████████████| 1.7 MB 41.2 MB/s 
[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod-&gt;pycaret) (0.10.2)
Requirement already satisfied: patsy&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels-&gt;pyod-&gt;pycaret) (0.5.2)
Collecting pynndescent&gt;=0.5
  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)
[K     |████████████████████████████████| 1.1 MB 38.5 MB/s 
[?25hBuilding wheels for collected packages: htmlmin, imagehash, databricks-cli, pyLDAvis, pyod, umap-learn, pynndescent
  Building wheel for htmlmin (setup.py) ... [?25l[?25hdone
  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=e3b75c8eee79619a12cedd3b632369a2955b57c93c63802a4c2732284c215696
  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655
  Building wheel for imagehash (setup.py) ... [?25l[?25hdone
  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=d7f8a6fe5d2a22ad0255e3b49324a5256cc1d6a086382d751c62801c6f8e60af
  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e
  Building wheel for databricks-cli (setup.py) ... [?25l[?25hdone
  Created wheel for databricks-cli: filename=databricks_cli-0.17.0-py3-none-any.whl size=141960 sha256=374b392a36d039a9db36341f4f77373544e118f264e946de6afc3df685b6f2a6
  Stored in directory: /root/.cache/pip/wheels/55/c3/db/33705569425fd2bdc9ea73051a8053fa26965c2bce8a146747
  Building wheel for pyLDAvis (setup.py) ... [?25l[?25hdone
  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135617 sha256=622de91d9e6d7774f7ebf96f7f8a8024bdd26fd58b3b1b64ed2b1c0c065ca25b
  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284
  Building wheel for pyod (setup.py) ... [?25l[?25hdone
  Created wheel for pyod: filename=pyod-1.0.2-py3-none-any.whl size=150272 sha256=6ed42bc4ee11714dd33f87144c4a3a23358181e9046b013a1ada303f164ffe02
  Stored in directory: /root/.cache/pip/wheels/e6/8f/06/5512935ed3c79659f612e8bb8f43cb51dd47c21973e0230997
  Building wheel for umap-learn (setup.py) ... [?25l[?25hdone
  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=2e291b651f239ed6f1623db5e3de3948bf354c3a1fe7c9f6c83f950cf4b33d26
  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821
  Building wheel for pynndescent (setup.py) ... [?25l[?25hdone
  Created wheel for pynndescent: filename=pynndescent-0.5.7-py3-none-any.whl size=54286 sha256=8ba2a720da2de07ca7a3a9448738941b79964439ff57c152ea33f0fd375b3e74
  Stored in directory: /root/.cache/pip/wheels/7f/2a/f8/7bd5dcec71bd5c669f6f574db3113513696b98f3f9b51f496c
Successfully built htmlmin imagehash databricks-cli pyLDAvis pyod umap-learn pynndescent
Installing collected packages: markupsafe, numpy, tangled-up-in-unicode, smmap, scipy, multimethod, websocket-client, visions, srsly, requests, pyjwt, plac, Mako, imagehash, gitdb, catalogue, thinc, querystring-parser, pyyaml, pynndescent, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, yellowbrick, umap-learn, spacy, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret
  Attempting uninstall: markupsafe
    Found existing installation: MarkupSafe 2.0.1
    Uninstalling MarkupSafe-2.0.1:
      Successfully uninstalled MarkupSafe-2.0.1
  Attempting uninstall: numpy
    Found existing installation: numpy 1.21.6
    Uninstalling numpy-1.21.6:
      Successfully uninstalled numpy-1.21.6
  Attempting uninstall: scipy
    Found existing installation: scipy 1.4.1
    Uninstalling scipy-1.4.1:
      Successfully uninstalled scipy-1.4.1
  Attempting uninstall: srsly
    Found existing installation: srsly 2.4.3
    Uninstalling srsly-2.4.3:
      Successfully uninstalled srsly-2.4.3
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
  Attempting uninstall: catalogue
    Found existing installation: catalogue 2.0.7
    Uninstalling catalogue-2.0.7:
      Successfully uninstalled catalogue-2.0.7
  Attempting uninstall: thinc
    Found existing installation: thinc 8.0.17
    Uninstalling thinc-8.0.17:
      Successfully uninstalled thinc-8.0.17
  Attempting uninstall: pyyaml
    Found existing installation: PyYAML 3.13
    Uninstalling PyYAML-3.13:
      Successfully uninstalled PyYAML-3.13
  Attempting uninstall: yellowbrick
    Found existing installation: yellowbrick 1.4
    Uninstalling yellowbrick-1.4:
      Successfully uninstalled yellowbrick-1.4
  Attempting uninstall: spacy
    Found existing installation: spacy 3.3.1
    Uninstalling spacy-3.3.1:
      Successfully uninstalled spacy-3.3.1
  Attempting uninstall: pandas-profiling
    Found existing installation: pandas-profiling 1.4.1
    Uninstalling pandas-profiling-1.4.1:
      Successfully uninstalled pandas-profiling-1.4.1
  Attempting uninstall: mlxtend
    Found existing installation: mlxtend 0.14.0
    Uninstalling mlxtend-0.14.0:
      Successfully uninstalled mlxtend-0.14.0
  Attempting uninstall: lightgbm
    Found existing installation: lightgbm 2.2.3
    Uninstalling lightgbm-2.2.3:
      Successfully uninstalled lightgbm-2.2.3
  Attempting uninstall: imbalanced-learn
    Found existing installation: imbalanced-learn 0.8.1
    Uninstalling imbalanced-learn-0.8.1:
      Successfully uninstalled imbalanced-learn-0.8.1
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
xarray-einstats 0.2.2 requires numpy&gt;=1.21, but you have numpy 1.19.5 which is incompatible.
tensorflow 2.8.2+zzzcolab20220527125636 requires numpy&gt;=1.20, but you have numpy 1.19.5 which is incompatible.
google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.
en-core-web-sm 3.3.0 requires spacy&lt;3.4.0,&gt;=3.3.0.dev0, but you have spacy 2.3.7 which is incompatible.
datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.
albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible.[0m
Successfully installed Boruta-0.3 Mako-1.2.1 alembic-1.8.0 catalogue-1.0.0 databricks-cli-0.17.0 docker-5.0.3 funcy-1.17 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 kmodes-0.12.1 lightgbm-3.3.2 markupsafe-2.1.1 mlflow-1.27.0 mlxtend-0.19.0 multimethod-1.8 numpy-1.19.5 pandas-profiling-3.2.0 phik-0.12.2 plac-1.1.3 prometheus-flask-exporter-0.20.2 pyLDAvis-3.2.2 pycaret-2.3.10 pyjwt-2.4.0 pynndescent-0.5.7 pyod-1.0.2 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.28.1 scikit-plot-0.3.7 scipy-1.5.4 smmap-5.0.0 spacy-2.3.7 srsly-1.0.5 tangled-up-in-unicode-0.2.0 thinc-7.4.5 umap-learn-0.5.3 visions-0.7.4 websocket-client-1.3.3 yellowbrick-1.3.post1




Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting markupsafe==2.0.1
  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)
Installing collected packages: markupsafe
  Attempting uninstall: markupsafe
    Found existing installation: MarkupSafe 2.1.1
    Uninstalling MarkupSafe-2.1.1:
      Successfully uninstalled MarkupSafe-2.1.1
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
pandas-profiling 3.2.0 requires markupsafe~=2.1.1, but you have markupsafe 2.0.1 which is incompatible.
datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.[0m
Successfully installed markupsafe-2.0.1
</code></pre>
<ul>
<li>Pycaret을 구글 코랩에서 활성화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pycaret.utils <span class="keyword">import</span> enable_colab</span><br><span class="line">enable_colab()</span><br></pre></td></tr></table></figure>

<pre><code>Colab mode enabled.
</code></pre>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pycaret.datasets <span class="keyword">import</span> get_data</span><br><span class="line">dataset = get_data(<span class="string">&#x27;credit&#x27;</span>)</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>





  <div id="df-29e0804e-13fd-429f-bdf5-165511b24648">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LIMIT_BAL</th>
      <th>SEX</th>
      <th>EDUCATION</th>
      <th>MARRIAGE</th>
      <th>AGE</th>
      <th>PAY_1</th>
      <th>PAY_2</th>
      <th>PAY_3</th>
      <th>PAY_4</th>
      <th>PAY_5</th>
      <th>...</th>
      <th>BILL_AMT4</th>
      <th>BILL_AMT5</th>
      <th>BILL_AMT6</th>
      <th>PAY_AMT1</th>
      <th>PAY_AMT2</th>
      <th>PAY_AMT3</th>
      <th>PAY_AMT4</th>
      <th>PAY_AMT5</th>
      <th>PAY_AMT6</th>
      <th>default</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20000</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>24</td>
      <td>2</td>
      <td>2</td>
      <td>-1</td>
      <td>-1</td>
      <td>-2</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>689.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>90000</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>34</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>14331.0</td>
      <td>14948.0</td>
      <td>15549.0</td>
      <td>1518.0</td>
      <td>1500.0</td>
      <td>1000.0</td>
      <td>1000.0</td>
      <td>1000.0</td>
      <td>5000.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>50000</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>37</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>28314.0</td>
      <td>28959.0</td>
      <td>29547.0</td>
      <td>2000.0</td>
      <td>2019.0</td>
      <td>1200.0</td>
      <td>1100.0</td>
      <td>1069.0</td>
      <td>1000.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>50000</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>57</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>20940.0</td>
      <td>19146.0</td>
      <td>19131.0</td>
      <td>2000.0</td>
      <td>36681.0</td>
      <td>10000.0</td>
      <td>9000.0</td>
      <td>689.0</td>
      <td>679.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>50000</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>37</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>19394.0</td>
      <td>19619.0</td>
      <td>20024.0</td>
      <td>2500.0</td>
      <td>1815.0</td>
      <td>657.0</td>
      <td>1000.0</td>
      <td>1000.0</td>
      <td>800.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-29e0804e-13fd-429f-bdf5-165511b24648')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-29e0804e-13fd-429f-bdf5-165511b24648 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-29e0804e-13fd-429f-bdf5-165511b24648&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset.info()</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>



<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 24000 entries, 0 to 23999
Data columns (total 24 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   LIMIT_BAL  24000 non-null  int64  
 1   SEX        24000 non-null  int64  
 2   EDUCATION  24000 non-null  int64  
 3   MARRIAGE   24000 non-null  int64  
 4   AGE        24000 non-null  int64  
 5   PAY_1      24000 non-null  int64  
 6   PAY_2      24000 non-null  int64  
 7   PAY_3      24000 non-null  int64  
 8   PAY_4      24000 non-null  int64  
 9   PAY_5      24000 non-null  int64  
 10  PAY_6      24000 non-null  int64  
 11  BILL_AMT1  24000 non-null  float64
 12  BILL_AMT2  24000 non-null  float64
 13  BILL_AMT3  24000 non-null  float64
 14  BILL_AMT4  24000 non-null  float64
 15  BILL_AMT5  24000 non-null  float64
 16  BILL_AMT6  24000 non-null  float64
 17  PAY_AMT1   24000 non-null  float64
 18  PAY_AMT2   24000 non-null  float64
 19  PAY_AMT3   24000 non-null  float64
 20  PAY_AMT4   24000 non-null  float64
 21  PAY_AMT5   24000 non-null  float64
 22  PAY_AMT6   24000 non-null  float64
 23  default    24000 non-null  int64  
dtypes: float64(12), int64(12)
memory usage: 4.4 MB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = dataset.sample(frac=<span class="number">0.95</span>, random_state=<span class="number">786</span>)</span><br><span class="line">data_unseen = dataset.drop(data.index)</span><br><span class="line">data.reset_index(inplace=<span class="literal">True</span>, drop=<span class="literal">True</span>)</span><br><span class="line">data_unseen.reset_index(inplace=<span class="literal">True</span>, drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Data for Modeling: &#x27;</span> + <span class="built_in">str</span>(data.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Unseen Data For Predictions: &#x27;</span> + <span class="built_in">str</span>(data_unseen.shape))</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>



<pre><code>Data for Modeling: (22800, 24)
Unseen Data For Predictions: (1200, 24)
</code></pre>
<ul>
<li>setup</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jinja2</span><br><span class="line"><span class="keyword">from</span> pycaret.classification <span class="keyword">import</span> *</span><br><span class="line">exp_clf101 = setup(data = data, </span><br><span class="line">                   target = <span class="string">&#x27;default&#x27;</span>, </span><br><span class="line">                   pca = <span class="literal">True</span>, pca_components = <span class="number">10</span>,</span><br><span class="line">                   session_id=<span class="number">123</span>) </span><br></pre></td></tr></table></figure>



  <div id="df-7f4d956a-b4cb-43a7-b24f-2da9353f8d09">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Description</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>session_id</td>
      <td>123</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Target</td>
      <td>default</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Target Type</td>
      <td>Binary</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Label Encoded</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Original Data</td>
      <td>(22800, 24)</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Missing Values</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Numeric Features</td>
      <td>14</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Categorical Features</td>
      <td>9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Ordinal Features</td>
      <td>False</td>
    </tr>
    <tr>
      <th>9</th>
      <td>High Cardinality Features</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10</th>
      <td>High Cardinality Method</td>
      <td>None</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Transformed Train Set</td>
      <td>(15959, 10)</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Transformed Test Set</td>
      <td>(6841, 10)</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Shuffle Train-Test</td>
      <td>True</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Stratify Train-Test</td>
      <td>False</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Fold Generator</td>
      <td>StratifiedKFold</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Fold Number</td>
      <td>10</td>
    </tr>
    <tr>
      <th>17</th>
      <td>CPU Jobs</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Use GPU</td>
      <td>False</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Log Experiment</td>
      <td>False</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Experiment Name</td>
      <td>clf-default-name</td>
    </tr>
    <tr>
      <th>21</th>
      <td>USI</td>
      <td>1256</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Imputation Type</td>
      <td>simple</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Iterative Imputation Iteration</td>
      <td>None</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Numeric Imputer</td>
      <td>mean</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Iterative Imputation Numeric Model</td>
      <td>None</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Categorical Imputer</td>
      <td>constant</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Iterative Imputation Categorical Model</td>
      <td>None</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Unknown Categoricals Handling</td>
      <td>least_frequent</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Normalize</td>
      <td>False</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Normalize Method</td>
      <td>None</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Transformation</td>
      <td>False</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Transformation Method</td>
      <td>None</td>
    </tr>
    <tr>
      <th>33</th>
      <td>PCA</td>
      <td>True</td>
    </tr>
    <tr>
      <th>34</th>
      <td>PCA Method</td>
      <td>linear</td>
    </tr>
    <tr>
      <th>35</th>
      <td>PCA Components</td>
      <td>10</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Ignore Low Variance</td>
      <td>False</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Combine Rare Levels</td>
      <td>False</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Rare Level Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Numeric Binning</td>
      <td>False</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Remove Outliers</td>
      <td>False</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Outliers Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Remove Multicollinearity</td>
      <td>False</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Multicollinearity Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Remove Perfect Collinearity</td>
      <td>True</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Clustering</td>
      <td>False</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Clustering Iteration</td>
      <td>None</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Polynomial Features</td>
      <td>False</td>
    </tr>
    <tr>
      <th>48</th>
      <td>Polynomial Degree</td>
      <td>None</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Trignometry Features</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50</th>
      <td>Polynomial Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>51</th>
      <td>Group Features</td>
      <td>False</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Feature Selection</td>
      <td>False</td>
    </tr>
    <tr>
      <th>53</th>
      <td>Feature Selection Method</td>
      <td>classic</td>
    </tr>
    <tr>
      <th>54</th>
      <td>Features Selection Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>55</th>
      <td>Feature Interaction</td>
      <td>False</td>
    </tr>
    <tr>
      <th>56</th>
      <td>Feature Ratio</td>
      <td>False</td>
    </tr>
    <tr>
      <th>57</th>
      <td>Interaction Threshold</td>
      <td>None</td>
    </tr>
    <tr>
      <th>58</th>
      <td>Fix Imbalance</td>
      <td>False</td>
    </tr>
    <tr>
      <th>59</th>
      <td>Fix Imbalance Method</td>
      <td>SMOTE</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7f4d956a-b4cb-43a7-b24f-2da9353f8d09')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-7f4d956a-b4cb-43a7-b24f-2da9353f8d09 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-7f4d956a-b4cb-43a7-b24f-2da9353f8d09&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>



<h2 id="모델링"><a href="#모델링" class="headerlink" title="모델링"></a>모델링</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_model = compare_models()</span><br></pre></td></tr></table></figure>



  <div id="df-21491840-e08f-4856-9210-d2c4ce582989">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>AUC</th>
      <th>Recall</th>
      <th>Prec.</th>
      <th>F1</th>
      <th>Kappa</th>
      <th>MCC</th>
      <th>TT (Sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ridge</th>
      <td>Ridge Classifier</td>
      <td>0.8254</td>
      <td>0.0000</td>
      <td>0.3637</td>
      <td>0.6913</td>
      <td>0.4764</td>
      <td>0.3836</td>
      <td>0.4122</td>
      <td>0.048</td>
    </tr>
    <tr>
      <th>lda</th>
      <td>Linear Discriminant Analysis</td>
      <td>0.8247</td>
      <td>0.7634</td>
      <td>0.3755</td>
      <td>0.6794</td>
      <td>0.4835</td>
      <td>0.3884</td>
      <td>0.4132</td>
      <td>0.321</td>
    </tr>
    <tr>
      <th>gbc</th>
      <td>Gradient Boosting Classifier</td>
      <td>0.8226</td>
      <td>0.7789</td>
      <td>0.3551</td>
      <td>0.6806</td>
      <td>0.4664</td>
      <td>0.3725</td>
      <td>0.4010</td>
      <td>5.241</td>
    </tr>
    <tr>
      <th>ada</th>
      <td>Ada Boost Classifier</td>
      <td>0.8221</td>
      <td>0.7697</td>
      <td>0.3505</td>
      <td>0.6811</td>
      <td>0.4626</td>
      <td>0.3690</td>
      <td>0.3983</td>
      <td>1.220</td>
    </tr>
    <tr>
      <th>lightgbm</th>
      <td>Light Gradient Boosting Machine</td>
      <td>0.8210</td>
      <td>0.7750</td>
      <td>0.3609</td>
      <td>0.6679</td>
      <td>0.4683</td>
      <td>0.3721</td>
      <td>0.3977</td>
      <td>0.444</td>
    </tr>
    <tr>
      <th>rf</th>
      <td>Random Forest Classifier</td>
      <td>0.8199</td>
      <td>0.7598</td>
      <td>0.3663</td>
      <td>0.6601</td>
      <td>0.4707</td>
      <td>0.3727</td>
      <td>0.3965</td>
      <td>2.864</td>
    </tr>
    <tr>
      <th>et</th>
      <td>Extra Trees Classifier</td>
      <td>0.8092</td>
      <td>0.7377</td>
      <td>0.3677</td>
      <td>0.6047</td>
      <td>0.4571</td>
      <td>0.3497</td>
      <td>0.3657</td>
      <td>2.473</td>
    </tr>
    <tr>
      <th>lr</th>
      <td>Logistic Regression</td>
      <td>0.7814</td>
      <td>0.6410</td>
      <td>0.0003</td>
      <td>0.1000</td>
      <td>0.0006</td>
      <td>0.0003</td>
      <td>0.0034</td>
      <td>1.039</td>
    </tr>
    <tr>
      <th>dummy</th>
      <td>Dummy Classifier</td>
      <td>0.7814</td>
      <td>0.5000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.032</td>
    </tr>
    <tr>
      <th>knn</th>
      <td>K Neighbors Classifier</td>
      <td>0.7547</td>
      <td>0.5939</td>
      <td>0.1763</td>
      <td>0.3719</td>
      <td>0.2388</td>
      <td>0.1145</td>
      <td>0.1259</td>
      <td>0.910</td>
    </tr>
    <tr>
      <th>dt</th>
      <td>Decision Tree Classifier</td>
      <td>0.7293</td>
      <td>0.6147</td>
      <td>0.4104</td>
      <td>0.3878</td>
      <td>0.3986</td>
      <td>0.2242</td>
      <td>0.2245</td>
      <td>0.350</td>
    </tr>
    <tr>
      <th>svm</th>
      <td>SVM - Linear Kernel</td>
      <td>0.7277</td>
      <td>0.0000</td>
      <td>0.1017</td>
      <td>0.1671</td>
      <td>0.0984</td>
      <td>0.0067</td>
      <td>0.0075</td>
      <td>0.465</td>
    </tr>
    <tr>
      <th>qda</th>
      <td>Quadratic Discriminant Analysis</td>
      <td>0.5098</td>
      <td>0.5473</td>
      <td>0.6141</td>
      <td>0.2472</td>
      <td>0.3488</td>
      <td>0.0600</td>
      <td>0.0805</td>
      <td>0.179</td>
    </tr>
    <tr>
      <th>nb</th>
      <td>Naive Bayes</td>
      <td>0.3760</td>
      <td>0.6442</td>
      <td>0.8845</td>
      <td>0.2441</td>
      <td>0.3826</td>
      <td>0.0608</td>
      <td>0.1207</td>
      <td>0.038</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-21491840-e08f-4856-9210-d2c4ce582989')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-21491840-e08f-4856-9210-d2c4ce582989 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-21491840-e08f-4856-9210-d2c4ce582989&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>



<ul>
<li>가장 좋은 모델을 뽑아주세욧!</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(best_model)</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>



<pre><code>RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=123, solver=&#39;auto&#39;,
                tol=0.001)
</code></pre>
<ul>
<li><p>모델 생성</p>
</li>
<li></li>
<li><p>모델 생성</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_model = create_model(<span class="string">&#x27;knn&#x27;</span>)</span><br></pre></td></tr></table></figure>



  <div id="df-44a04167-0b6b-4583-89b4-ca7d8baaab2f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
      <th>AUC</th>
      <th>Recall</th>
      <th>Prec.</th>
      <th>F1</th>
      <th>Kappa</th>
      <th>MCC</th>
    </tr>
    <tr>
      <th>Fold</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.7469</td>
      <td>0.6020</td>
      <td>0.1920</td>
      <td>0.3545</td>
      <td>0.2491</td>
      <td>0.1128</td>
      <td>0.1204</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.7550</td>
      <td>0.5894</td>
      <td>0.2092</td>
      <td>0.3883</td>
      <td>0.2719</td>
      <td>0.1402</td>
      <td>0.1500</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.7506</td>
      <td>0.5883</td>
      <td>0.1576</td>
      <td>0.3459</td>
      <td>0.2165</td>
      <td>0.0923</td>
      <td>0.1024</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.7419</td>
      <td>0.5818</td>
      <td>0.1519</td>
      <td>0.3136</td>
      <td>0.2046</td>
      <td>0.0723</td>
      <td>0.0790</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.7563</td>
      <td>0.5908</td>
      <td>0.1490</td>
      <td>0.3611</td>
      <td>0.2110</td>
      <td>0.0954</td>
      <td>0.1085</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.7550</td>
      <td>0.5997</td>
      <td>0.1748</td>
      <td>0.3720</td>
      <td>0.2378</td>
      <td>0.1139</td>
      <td>0.1255</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.7638</td>
      <td>0.5890</td>
      <td>0.1891</td>
      <td>0.4125</td>
      <td>0.2593</td>
      <td>0.1413</td>
      <td>0.1565</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.7613</td>
      <td>0.6240</td>
      <td>0.1633</td>
      <td>0.3904</td>
      <td>0.2303</td>
      <td>0.1163</td>
      <td>0.1318</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.7619</td>
      <td>0.5988</td>
      <td>0.1862</td>
      <td>0.4037</td>
      <td>0.2549</td>
      <td>0.1356</td>
      <td>0.1500</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.7549</td>
      <td>0.5756</td>
      <td>0.1897</td>
      <td>0.3771</td>
      <td>0.2524</td>
      <td>0.1246</td>
      <td>0.1351</td>
    </tr>
    <tr>
      <th>Mean</th>
      <td>0.7547</td>
      <td>0.5939</td>
      <td>0.1763</td>
      <td>0.3719</td>
      <td>0.2388</td>
      <td>0.1145</td>
      <td>0.1259</td>
    </tr>
    <tr>
      <th>Std</th>
      <td>0.0065</td>
      <td>0.0126</td>
      <td>0.0191</td>
      <td>0.0279</td>
      <td>0.0214</td>
      <td>0.0214</td>
      <td>0.0230</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-44a04167-0b6b-4583-89b4-ca7d8baaab2f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-44a04167-0b6b-4583-89b4-ca7d8baaab2f button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-44a04167-0b6b-4583-89b4-ca7d8baaab2f&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;n_neighbors&#x27;</span> : np.arange(<span class="number">0</span>, <span class="number">50</span>, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">tunned_knn = tune_model(knn_model, custom_grid=params)</span><br><span class="line"><span class="built_in">print</span>(tunned_knn)</span><br></pre></td></tr></table></figure>



  <div id="df-e0086458-f318-4e5f-9c06-c6167a9a4b9e">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
      <th>AUC</th>
      <th>Recall</th>
      <th>Prec.</th>
      <th>F1</th>
      <th>Kappa</th>
      <th>MCC</th>
    </tr>
    <tr>
      <th>Fold</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.7813</td>
      <td>0.6482</td>
      <td>0.0372</td>
      <td>0.5000</td>
      <td>0.0693</td>
      <td>0.0402</td>
      <td>0.0876</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.7807</td>
      <td>0.6436</td>
      <td>0.0315</td>
      <td>0.4783</td>
      <td>0.0591</td>
      <td>0.0330</td>
      <td>0.0759</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.7744</td>
      <td>0.6563</td>
      <td>0.0315</td>
      <td>0.3333</td>
      <td>0.0576</td>
      <td>0.0206</td>
      <td>0.0403</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.7845</td>
      <td>0.6589</td>
      <td>0.0659</td>
      <td>0.5610</td>
      <td>0.1179</td>
      <td>0.0754</td>
      <td>0.1345</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.7826</td>
      <td>0.6645</td>
      <td>0.0315</td>
      <td>0.5500</td>
      <td>0.0596</td>
      <td>0.0368</td>
      <td>0.0903</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.7794</td>
      <td>0.6477</td>
      <td>0.0544</td>
      <td>0.4634</td>
      <td>0.0974</td>
      <td>0.0539</td>
      <td>0.0961</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.7826</td>
      <td>0.6278</td>
      <td>0.0630</td>
      <td>0.5238</td>
      <td>0.1125</td>
      <td>0.0688</td>
      <td>0.1214</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.7751</td>
      <td>0.6702</td>
      <td>0.0372</td>
      <td>0.3611</td>
      <td>0.0675</td>
      <td>0.0278</td>
      <td>0.0523</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.7813</td>
      <td>0.6409</td>
      <td>0.0630</td>
      <td>0.5000</td>
      <td>0.1120</td>
      <td>0.0662</td>
      <td>0.1146</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.7881</td>
      <td>0.6426</td>
      <td>0.0661</td>
      <td>0.6389</td>
      <td>0.1198</td>
      <td>0.0822</td>
      <td>0.1548</td>
    </tr>
    <tr>
      <th>Mean</th>
      <td>0.7810</td>
      <td>0.6501</td>
      <td>0.0482</td>
      <td>0.4910</td>
      <td>0.0873</td>
      <td>0.0505</td>
      <td>0.0968</td>
    </tr>
    <tr>
      <th>Std</th>
      <td>0.0039</td>
      <td>0.0119</td>
      <td>0.0148</td>
      <td>0.0861</td>
      <td>0.0255</td>
      <td>0.0206</td>
      <td>0.0338</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-e0086458-f318-4e5f-9c06-c6167a9a4b9e')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-e0086458-f318-4e5f-9c06-c6167a9a4b9e button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-e0086458-f318-4e5f-9c06-c6167a9a4b9e&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>



<pre><code>KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
                     metric_params=None, n_jobs=-1, n_neighbors=42, p=2,
                     weights=&#39;uniform&#39;)
</code></pre>
<ul>
<li>auc </li>
<li>최소 0.5</li>
<li>좋은 모델 기준 0.8 이상 </li>
<li>최고 1</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_model(tunned_knn, plot=<span class="string">&#x27;auc&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/images/PyCaret/output_19_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 의사결정트리</span></span><br><span class="line"><span class="comment"># plot_model(tunned_knn, plot=&#x27;feature&#x27;)</span></span><br><span class="line">plot_model(tunned_knn, plot=<span class="string">&#x27;confusion_matrix&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/images/PyCaret/output_20_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluate_model(tunned_knn)</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>




<pre><code>interactive(children=(ToggleButtons(description=&#39;Plot Type:&#39;, icons=(&#39;&#39;,), options=((&#39;Hyperparameters&#39;, &#39;param…
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">models()</span><br></pre></td></tr></table></figure>



<script src="/static/components/requirejs/require.js"></script>
<script>
  requirejs.config({
    paths: {
      base: '/static/base',
      plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',
    },
  });
</script>







  <div id="df-5101e29a-5cbb-4973-bd7d-860b0ca28b67">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Reference</th>
      <th>Turbo</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lr</th>
      <td>Logistic Regression</td>
      <td>sklearn.linear_model._logistic.LogisticRegression</td>
      <td>True</td>
    </tr>
    <tr>
      <th>knn</th>
      <td>K Neighbors Classifier</td>
      <td>sklearn.neighbors._classification.KNeighborsCl...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>nb</th>
      <td>Naive Bayes</td>
      <td>sklearn.naive_bayes.GaussianNB</td>
      <td>True</td>
    </tr>
    <tr>
      <th>dt</th>
      <td>Decision Tree Classifier</td>
      <td>sklearn.tree._classes.DecisionTreeClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>svm</th>
      <td>SVM - Linear Kernel</td>
      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>rbfsvm</th>
      <td>SVM - Radial Kernel</td>
      <td>sklearn.svm._classes.SVC</td>
      <td>False</td>
    </tr>
    <tr>
      <th>gpc</th>
      <td>Gaussian Process Classifier</td>
      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>
      <td>False</td>
    </tr>
    <tr>
      <th>mlp</th>
      <td>MLP Classifier</td>
      <td>sklearn.neural_network._multilayer_perceptron....</td>
      <td>False</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>Ridge Classifier</td>
      <td>sklearn.linear_model._ridge.RidgeClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>rf</th>
      <td>Random Forest Classifier</td>
      <td>sklearn.ensemble._forest.RandomForestClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>qda</th>
      <td>Quadratic Discriminant Analysis</td>
      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>ada</th>
      <td>Ada Boost Classifier</td>
      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>gbc</th>
      <td>Gradient Boosting Classifier</td>
      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>lda</th>
      <td>Linear Discriminant Analysis</td>
      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>
      <td>True</td>
    </tr>
    <tr>
      <th>et</th>
      <td>Extra Trees Classifier</td>
      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>lightgbm</th>
      <td>Light Gradient Boosting Machine</td>
      <td>lightgbm.sklearn.LGBMClassifier</td>
      <td>True</td>
    </tr>
    <tr>
      <th>dummy</th>
      <td>Dummy Classifier</td>
      <td>sklearn.dummy.DummyClassifier</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-5101e29a-5cbb-4973-bd7d-860b0ca28b67')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-5101e29a-5cbb-4973-bd7d-860b0ca28b67 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-5101e29a-5cbb-4973-bd7d-860b0ca28b67&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/PyCaret/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/PyCaret/output.renderimages/PyCaret/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>



</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-05T00:00:00.000Z" title="2022. 7. 5. 오전 9:00:00">2022-07-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:28:35.878Z" title="2022. 7. 6. 오후 12:28:35">2022-07-06</time></span><span class="level-item">8 minutes read (About 1180 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/05/day0705/">랜덤포레스트 &amp; 그레이디언트 부스팅 &amp; 주성분 분석</a></h1><div class="content"><h2 id="랜덤-포레스트"><a href="#랜덤-포레스트" class="headerlink" title="랜덤 포레스트"></a>랜덤 포레스트</h2><ul>
<li>Decision Tree (나무 1개)<ul>
<li>여러개 심음</li>
<li>샘플링</li>
<li>Feature Importances</li>
</ul>
</li>
<li>예측해야 할 행의 갯수, 100만개</li>
<li>컬럼의 갯수 200개 –&gt; 100개<ul>
<li>나무 100개를 심고 평균을 내자</li>
<li>나무 1개 당 컬럼을 10개로 </li>
<li>T1 mae : 20 &#x2F; T2 mae : 30 &#x2F; T3 mae 10, …. <ul>
<li>T1 ~ T100 mae :  20</li>
<li>feature importances</li>
</ul>
</li>
<li>샘플링 : 부트스트랩 샘플 (복원 추출)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라이브러리 불러오기 </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input, target 분리 </span></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델링</span></span><br><span class="line">rf = RandomForestClassifier(n_jobs=-<span class="number">1</span>, random_state = <span class="number">42</span>) <span class="comment">#n_jobs=-1 : 시스템에 있는 모든 코어를 사용</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모형 평가</span></span><br><span class="line">scores = cross_validate(rf, train_input, train_target, return_train_score = <span class="literal">True</span>, n_jobs =-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>0.9973541965122431 0.8905151032797809
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 특성 중요</span></span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="comment"># print(rf.feature_importances_)</span></span><br><span class="line"><span class="built_in">print</span>(rf.feature_importances_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0.23167441 0.50039841 0.26792718]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OOB </span></span><br><span class="line">rf = RandomForestClassifier(oob_score = <span class="literal">True</span>, n_jobs = -<span class="number">1</span>, random_state = <span class="number">42</span>)</span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.oob_score_)</span><br></pre></td></tr></table></figure>

<pre><code>0.8934000384837406
</code></pre>
<h2 id="그레이디언트-부스팅"><a href="#그레이디언트-부스팅" class="headerlink" title="그레이디언트 부스팅"></a>그레이디언트 부스팅</h2><ul>
<li>경사하강법의 원리를 이용함. </li>
<li>T1 ~ TN 증가하면서 오차를 보정해주며 정확성을 높임</li>
<li>랜덤포레스트와의 차이점 <ul>
<li>랜덤포레스트는 각 나무간 상호 연관성 없음</li>
<li>부스팅은 각 나무간 상호 연관성 있음</li>
</ul>
</li>
<li>단점<ul>
<li>속도가 너무 느려요</li>
</ul>
</li>
<li>대안<ul>
<li>XGBoost, LightGBM</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">gb = GradientBoostingClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb, train_input, train_target, return_train_score=<span class="literal">True</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8881086892152563 0.8720430147331015
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gb = GradientBoostingClassifier(n_estimators = <span class="number">500</span>, learning_rate = <span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb, train_input, train_target, return_train_score=<span class="literal">True</span>, n_jobs=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9464595437171814 0.8780082549788999
</code></pre>
<ul>
<li>특성 중요도</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gb.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(gb.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.15872278 0.68010884 0.16116839]
</code></pre>
<p> p318</p>
<h2 id="주성분-분석"><a href="#주성분-분석" class="headerlink" title="주성분 분석"></a>주성분 분석</h2><ul>
<li>이론적으로 어려움</li>
<li>좌표계 공간 개념</li>
<li>직교 + 회전</li>
<li>공분산 등(통계관련내용)</li>
<li>Feature Engineering 기법</li>
<li>StandardScaler()</li>
<li>현 ML의 문제점 : 컬럼의 갯수 매우 많음</li>
<li>차원축소</li>
</ul>
<ul>
<li>특성이 많으면 훈련데이터에 쉽게 과대적합된다</li>
<li>특성을 줄여서 학습모델의 성능을 향상시킨다</li>
<li>모델의 학습시간을 감소시켜준다</li>
<li>대표적인 방법론 중 하나가 PCA, EFA</li>
</ul>
<ul>
<li>PCA vs EFA</li>
</ul>
<ul>
<li>EFA(탐색적 요인 분석), Factor Analysis</li>
</ul>
<ul>
<li>예) 국어, 수학, 과학, 영어</li>
<li>예) 국어40, 수학100, 과학100, 영어30 &#x2F; 위 학생은 언어영역은 수준이 낮은 편이나 수리영역은 매우 수준이 높습니다</li>
<li>예) 범주형 &amp; 수치데이터</li>
</ul>
<ul>
<li>PCA(주성분분석)</li>
</ul>
<ul>
<li>장비1, 장비2, 장비3, 장비4, ….</li>
<li>PC1, PC2, PC3, ….PCN</li>
<li>원래 가지고 있던 정보를 알 수 없음(정보손실)</li>
<li>범주형 데이터셋에는 사용 안됨</li>
<li>무조건 수치형 데이터에만 사용</li>
<li>PCA 실행 전, 반드시 표준화처리(스케일링 실행)</li>
</ul>
<p> p.320</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-07-05 04:58:41--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11
Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-07-05 04:58:41--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 192.30.255.112
Connecting to github.com (github.com)|192.30.255.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-07-05 04:58:41--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.04s   

2022-07-05 04:58:41 (64.2 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">fruits = np. load(<span class="string">&#x27;/content/fruits_300.npy&#x27;</span>)</span><br><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fruits_2d.shape</span><br></pre></td></tr></table></figure>




<pre><code>(300, 10000)
</code></pre>
<ul>
<li>PCA</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">50</span>)</span><br><span class="line">pca.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>PCA(n_components=50)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.components_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(50, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(pca.components_.reshape(-<span class="number">1</span>,<span class="number">100</span>,<span class="number">100</span>))</span><br></pre></td></tr></table></figure>


<p><img src="/images/0705/output_22_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 머신러닝에서 컬럼갯수를 10000개에서 50개로 줄임</span></span><br><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(300, 50)
</code></pre>
<ul>
<li>훈련데이터, 테스트 데이터 분리</li>
</ul>
<h2 id="설명된-분산"><a href="#설명된-분산" class="headerlink" title="설명된 분산"></a>설명된 분산</h2><ul>
<li>주성분이 원본데이터의 분산을 얼마나 잘 나타내는지 기록한 값</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_))</span><br></pre></td></tr></table></figure>

<pre><code>0.9214955656462601
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(pca.explained_variance_ratio_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0705/output_27_0.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_[:]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9214955656462601
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-04T00:00:00.000Z" title="2022. 7. 4. 오전 9:00:00">2022-07-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:28:35.877Z" title="2022. 7. 6. 오후 12:28:35">2022-07-06</time></span><span class="level-item">2 hours read (About 15453 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/04/day0704/">확률적경사하강법 &amp; 결정트리</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 확률적 경사 하강법</span></span><br><span class="line">- 점진적 학습(step, 보폭)</span><br><span class="line">- 학습률</span><br><span class="line">- XGBoost, LightGBM, 딥러닝(이미지분류, 자연어처리, 옵티마이저)</span><br></pre></td></tr></table></figure>

<h3 id=""><a href="#" class="headerlink" title=""></a></h3><ul>
<li>신경망 이미지 데이터, 자연어</li>
<li>자율주행 하루 데이터 1TB –&gt; 학습</li>
<li>한꺼번에 다 모델을 학습하기 어려움</li>
</ul>
<ul>
<li>샘플링, 배치, 에포크, 오차가 가장 적은 지점을 찾아야 한다</li>
</ul>
<ul>
<li>결론적으로 확률적 경사 하강법</li>
</ul>
<h2 id="손실함수"><a href="#손실함수" class="headerlink" title="손실함수"></a>손실함수</h2><ul>
<li>로지스틱 손실함수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;https://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 159 entries, 0 to 158
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Species   159 non-null    object 
 1   Weight    159 non-null    float64
 2   Length    159 non-null    float64
 3   Diagonal  159 non-null    float64
 4   Height    159 non-null    float64
 5   Width     159 non-null    float64
dtypes: float64(5), object(1)
memory usage: 7.6+ KB
</code></pre>
<ul>
<li>입력데이터와 타깃데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>,<span class="string">&#x27;Length&#x27;</span>,<span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]].to_numpy()</span><br><span class="line">fish_target = fish[[<span class="string">&#x27;Species&#x27;</span>]].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.773109243697479
0.775


/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sc.partial_fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8151260504201681
0.85


/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 에포크와 과대/ 과소적합</span></span><br><span class="line">- 에포크 숫자가 적으면 -&gt; 덜 학습</span><br><span class="line">- early_stoping</span><br><span class="line"> + 에포크 숫자를 <span class="number">1000</span>, 손실 <span class="number">10</span>, <span class="number">9</span>, <span class="number">8</span>,,<span class="number">3</span></span><br><span class="line"> + <span class="number">3</span>에 도달한 시점이 <span class="number">150</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, random_state = <span class="number">42</span>)</span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 300번 에포크 훈련을 반복</span></span><br><span class="line"><span class="comment"># 훈련 할때마다 train_score, test_score 추가를 한다</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">300</span>):</span><br><span class="line">  sc.partial_fit(train_scaled, train_target, classes=classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled, train_target)) </span><br><span class="line">  test_score.append(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line">plt.plot(train_score)</span><br><span class="line">plt.plot(test_score)</span><br><span class="line">plt.legend([<span class="string">&quot;train&quot;</span>, <span class="string">&quot;test&quot;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_14_0.png"></p>
<h2 id="결정트리"><a href="#결정트리" class="headerlink" title="결정트리"></a>결정트리</h2><ul>
<li>wine데이터 가져오기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.head()</span><br></pre></td></tr></table></figure>





  <div id="df-608990b6-164e-4c58-b650-84617bfdd0a0">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-608990b6-164e-4c58-b650-84617bfdd0a0')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-608990b6-164e-4c58-b650-84617bfdd0a0 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-608990b6-164e-4c58-b650-84617bfdd0a0&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0704/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0704/output.renderimages/0704/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)
memory usage: 203.2 KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.describe()</span><br></pre></td></tr></table></figure>





  <div id="df-02cb83bf-d4f5-4092-9f7e-747daf214f5f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.491801</td>
      <td>5.443235</td>
      <td>3.218501</td>
      <td>0.753886</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.192712</td>
      <td>4.757804</td>
      <td>0.160787</td>
      <td>0.430779</td>
    </tr>
    <tr>
      <th>min</th>
      <td>8.000000</td>
      <td>0.600000</td>
      <td>2.720000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>9.500000</td>
      <td>1.800000</td>
      <td>3.110000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.300000</td>
      <td>3.000000</td>
      <td>3.210000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11.300000</td>
      <td>8.100000</td>
      <td>3.320000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.900000</td>
      <td>65.800000</td>
      <td>4.010000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-02cb83bf-d4f5-4092-9f7e-747daf214f5f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-02cb83bf-d4f5-4092-9f7e-747daf214f5f button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-02cb83bf-d4f5-4092-9f7e-747daf214f5f&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;images/0704/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.images/0704/output.renderimages/0704/output(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target,test_size=<span class="number">0.2</span>,random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
</code></pre>
<ul>
<li>모델 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.996921300750433
0.8592307692307692
</code></pre>
<p>훈련세트에 대한 점수가 높다 &#x2F; 과대적합</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_29_0.png"></p>
<ul>
<li>모델 만들기 (연습)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree </span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">8</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.9003271117952665
0.8576923076923076
</code></pre>
<p><img src="/images/0704/output_31_1.png"></p>
<h2 id="노드란-무엇인가"><a href="#노드란-무엇인가" class="headerlink" title="노드란 무엇인가?"></a>노드란 무엇인가?</h2><ul>
<li>0 이면 레드와인</li>
<li>1 이면 화이트와인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt, max_depth=<span class="number">1</span>, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_33_0.png"></p>
<ul>
<li>불순도</li>
</ul>
<ul>
<li>비율</li>
<li>레드와인 5:5 화이트와인 (균등하게 섞여 있을때 0.5로 가장높다)</li>
<li>한 범주 안에서 서로 다른 데이터가 얼마나 섞여 있는지를 나타냄</li>
<li>흰색과 검은색이 각각 50개 섞여있다</li>
<li>불순도 최대 0.5</li>
<li>흰색과 검은색이 완전 100% 분리가 됨</li>
<li>흰색 노드 불순도 최소 0</li>
<li>검은색 노드 불순도 최소 0</li>
</ul>
<ul>
<li>엔트로피(Entropy)<br> +불확실한 정도를 의미한다 (0-1사이)</li>
</ul>
<ul>
<li>흰색과 검은색이 각각 50개 섞여있다</li>
<li>엔트로피 최대 1</li>
<li>흰색과 검은색이 완전 100%분리됨</li>
<li>흰색노드 엔트로피 최소0</li>
<li>검은색노드 엔트로피 최소0</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree </span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(criterion = <span class="string">&#x27;entropy&#x27;</span>, max_depth = <span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt, max_depth=<span class="number">1</span>, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.7579372715027901
0.7376923076923076
</code></pre>
<p><img src="/images/0704/output_35_1.png"></p>
<h2 id="특성-중요도"><a href="#특성-중요도" class="headerlink" title="특성 중요도"></a>특성 중요도</h2><ul>
<li>어떤 특성이 결정트리 모델에 영향을 주었는가?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(dt.feature_importances_) <span class="comment">#feature_importances_ : 인과관계와는 관계가 없다, 인과관계는 P-Value로 확인한다</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.15533444 0.6675247  0.17714086]
</code></pre>
<h2 id="현업에서의-적용"><a href="#현업에서의-적용" class="headerlink" title="현업에서의 적용"></a>현업에서의 적용</h2><ul>
<li>현업에서 DescisionTreeClassifier(1970년대)</li>
<li>랜던포레스트, XGboost pamameters, 하이퍼파라미터 매우 많음</li>
</ul>
<p>p242</p>
<h2 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h2><ul>
<li>훈련세트와 테스트세트</li>
<li>훈련: 교과서 공부하는 것 훈련세트, 모의평가</li>
<li>검증: 강남대성 모의고사</li>
<li>테스트: 6월 &#x2F; 9월</li>
<li>실전: 수능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련 80%</span></span><br><span class="line"><span class="comment"># 테스트 20%</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target,test_size=<span class="number">0.2</span>,random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((5197, 3), (1300, 3), (5197,), (1300,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련80% </span></span><br><span class="line"><span class="comment"># 검증 20%</span></span><br><span class="line">sub_input, val_input, sub_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target,test_size=<span class="number">0.2</span>,random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sub_input.shape, val_input.shape, sub_target.shape, val_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((4157, 3), (1040, 3), (4157,), (1040,))
</code></pre>
<ul>
<li>모형 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt=DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input, sub_target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;훈련성과&quot;</span>,dt.score(sub_input, sub_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;검증성과&quot;</span>,dt.score(val_input, val_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;마지막최종&quot;</span>,dt.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>훈련성과 0.9971133028626413
검증성과 0.864423076923077
마지막최종 0.8569230769230769
</code></pre>
<h2 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h2><ul>
<li>데이터셋을 반복 분할</li>
<li>For loop</li>
<li>샘플링 편향적일 수 있음</li>
<li>교차검증을 한다고 해서, 정확도가 무조건 올라간다?(x)</li>
<li>모형을 안정적으로 만들어 준다</li>
</ul>
<ul>
<li>과대 적합 방지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line">df = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터를 K폴드로 나눈다</span></span><br><span class="line">folds = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx, valid_idx <span class="keyword">in</span> folds.split(df):</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;훈련데이터:<span class="subst">&#123;df[train_idx]&#125;</span>,검증데이터:<span class="subst">&#123;df[valid_idx]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>훈련데이터:[ 2  3  5  6  7  8  9 10],검증데이터:[1 4]
훈련데이터:[ 1  2  4  5  6  8  9 10],검증데이터:[3 7]
훈련데이터:[ 1  2  3  4  6  7  9 10],검증데이터:[5 8]
훈련데이터:[ 1  2  3  4  5  7  8 10],검증데이터:[6 9]
훈련데이터:[1 3 4 5 6 7 8 9],검증데이터:[ 2 10]
</code></pre>
<ul>
<li>교차검증 함수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(dt, train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균&quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.01242208, 0.0106051 , 0.01989627, 0.01051641, 0.01058054]), &#39;score_time&#39;: array([0.00130367, 0.00125098, 0.0013361 , 0.00134611, 0.00127673]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
평균 0.855300214703487
</code></pre>
<ul>
<li>StratifiedKFold 사용 (이것까지 들어가면 좋은 코드)</li>
<li>참조할만한 좋은 코드를 찾는 것도 실력</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">splitter = StratifiedKFold(n_splits=<span class="number">10</span>, shuffle = <span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv = splitter)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.0142889 , 0.01287746, 0.01375127, 0.01249719, 0.01662874,
       0.01322246, 0.01277661, 0.01421905, 0.0130713 , 0.01299787]), &#39;score_time&#39;: array([0.00124955, 0.00112534, 0.0013597 , 0.00117397, 0.00105834,
       0.00120282, 0.0014286 , 0.00127149, 0.00107288, 0.00111914]), &#39;test_score&#39;: array([0.83461538, 0.87884615, 0.85384615, 0.85384615, 0.84615385,
       0.87307692, 0.85961538, 0.85549133, 0.85163776, 0.86705202])&#125;
평균: 0.8574181117533719
</code></pre>
<h2 id="하이퍼-파라미터-튜닝"><a href="#하이퍼-파라미터-튜닝" class="headerlink" title="하이퍼 파라미터 튜닝"></a>하이퍼 파라미터 튜닝</h2><ul>
<li>그리드 서치 (용어기억)</li>
</ul>
<ul>
<li>사람이 수동적으로 입력</li>
<li>Max_Depth:[1,3,7]</li>
</ul>
<ul>
<li>랜덤 서치 (용어기억)</li>
</ul>
<ul>
<li>사람이 범위만 지정</li>
<li>Max_Depth: 1-10 &#x2F; by random</li>
</ul>
<ul>
<li>베이지안 옵티마이제이션</li>
<li>사람의 개입 없이 하이퍼 파라미터 튜닝을 자동으로 수행하는 기술을 AutoML이라고 한다</li>
</ul>
<ul>
<li>예)PyCaret</li>
</ul>
<ul>
<li>각 모델마다 적게는 1-2개에서 , 많게는 5-6개의 매개변수를 제공한다</li>
</ul>
<ul>
<li>XGBoost 100개….?</li>
</ul>
<ul>
<li>하이퍼파라미터와 동시에 교차검증을 수행</li>
</ul>
<ul>
<li>미친짓</li>
</ul>
<p>교차검증 5번<br>교차검증 1회 실행시 Max Depth 3번 적용</p>
<ul>
<li><p>총 결괏값 3 X 5 나온다</p>
</li>
<li><p>Max Depth &#x3D; 1,3,7</p>
</li>
<li><p>Criterion &#x3D; gini, entropy</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>:[<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>]&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003,
                                                   0.0004, 0.0005]&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9615162593804117
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;min_impurity_decrease&#39;: 0.0001&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">best_index=np.argmax(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;params&#x27;</span>][best_index])</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;min_impurity_decrease&#39;: 0.0001&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>:np.arange(<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.0001</span>),</span><br><span class="line">          <span class="string">&#x27;max_depth&#x27;</span>:<span class="built_in">range</span>(<span class="number">5</span>,<span class="number">20</span>,<span class="number">1</span>),</span><br><span class="line">          <span class="string">&#x27;min_samples_split&#x27;</span>:<span class="built_in">range</span>(<span class="number">2</span>,<span class="number">100</span>,<span class="number">10</span>)&#125; </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;max_depth&#39;: range(5, 20),
                         &#39;min_impurity_decrease&#39;: array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,
       0.0009]),
                         &#39;min_samples_split&#39;: range(2, 100, 10)&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;max_depth&#39;: 14, &#39;min_impurity_decrease&#39;: 0.0004, &#39;min_samples_split&#39;: 12&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8683865773302731
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-01T00:00:00.000Z" title="2022. 7. 1. 오전 9:00:00">2022-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:28:35.874Z" title="2022. 7. 6. 오후 12:28:35">2022-07-06</time></span><span class="level-item">7 minutes read (About 1084 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/01/day0701_ch03/">최근접 이웃회귀2</a></h1><div class="content"><h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(perch_length.shape, perch_weight.shape)</span><br><span class="line">      </span><br></pre></td></tr></table></figure>

<pre><code>(56,) (56,)
</code></pre>
<h2 id="훈련-세트와-테스트-세트로-나눈-후-1차원-gt-2차원-배열로-변환"><a href="#훈련-세트와-테스트-세트로-나눈-후-1차원-gt-2차원-배열로-변환" class="headerlink" title="훈련 세트와 테스트 세트로 나눈 후, 1차원 -&gt; 2차원 배열로 변환"></a>훈련 세트와 테스트 세트로 나눈 후, 1차원 -&gt; 2차원 배열로 변환</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<ul>
<li>1차원 -&gt; 2차원 배열</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = train_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42, 1), (14, 1))
</code></pre>
<h2 id="데이터-시각화-gt-데이터-재가공"><a href="#데이터-시각화-gt-데이터-재가공" class="headerlink" title="데이터 시각화 -&gt; 데이터 재가공"></a>데이터 시각화 -&gt; 데이터 재가공</h2><ul>
<li>모델링</li>
</ul>
<p>최근접 이웃개수를 3개로 하는 모델을 훈련한다 (기본값은 5개)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsRegressor(n_neighbors=3)
</code></pre>
<ul>
<li>모델 평가</li>
</ul>
<h2 id="모델-예측"><a href="#모델-예측" class="headerlink" title="모델 예측"></a>모델 예측</h2><ul>
<li>서비스를 함</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 농어의 길이50cm -&gt; 농어의 무게?</span></span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<p>모델은 50cm농어의 무게를 1,033g정도로 예측했다. 그런데 이 농어의 실제 무게는 훨씬 더 많이 나간다. 어디서 문제가 발생한 것인가?</p>
<h2 id="모형-평가를-위한-시각화"><a href="#모형-평가를-위한-시각화" class="headerlink" title="모형 평가를 위한 시각화"></a>모형 평가를 위한 시각화</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 3개</span></span><br><span class="line">distance, indexes = knr.kneighbors([[<span class="number">50</span>]]) <span class="comment">#kneighbors()메서드:가장 가까운 이웃까지의 거리와 이웃의 샘플을 얻을 수 있음</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(distance, indexes)</span><br></pre></td></tr></table></figure>

<pre><code>[[6. 7. 7.]] [[34  8 14]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련세트의 산점도를 그린다</span></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련세트 중에서 이웃 샘플만 다시 그린다</span></span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어데이터</span></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0701_ch03/output_15_0.png"></p>
<ul>
<li>k-최근접 이웃회귀는 가장 가까운 샘플을 찾아 타깃을 평균한다</li>
<li>따라서 새로운 샘플이 훈련세트의 범위를 벗어나면 엉뚱한 값을 예측할 수 있다</li>
<li>예를 들어 길이가 100cm인 농어도 여전히 1033g으로 예측한다</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">distance, indexes = knr.kneighbors([[<span class="number">100</span>]])</span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line">plt.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(<span class="number">100</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0701_ch03/output_17_0.png"></p>
<h2 id="선형회귀"><a href="#선형회귀" class="headerlink" title="선형회귀"></a>선형회귀</h2><ul>
<li>p136</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어에 대해 예측</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1241.83860323]
</code></pre>
<h2 id="선형회귀의-모형"><a href="#선형회귀의-모형" class="headerlink" title="선형회귀의 모형"></a>선형회귀의 모형</h2><ul>
<li>기울기,  절편</li>
<li>coef_ : 기울기, 계수(coefficient) 또는 가중치(weight)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[39.01714496] -709.0186449535477
</code></pre>
<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 15에서 50까지 1차방정식 그래프를 그린다 </span></span><br><span class="line">plt.plot([<span class="number">15</span>,<span class="number">50</span>], [<span class="number">15</span>*lr.coef_+lr.intercept_, <span class="number">50</span>*lr.coef_+lr.intercept_])</span><br><span class="line"></span><br><span class="line"><span class="comment">#50cm 농어 데이터 </span></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1241.8</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0701_ch03/output_23_0.png"></p>
<ul>
<li>직선대로 예측하면 농어의 무게가 0g이하로 내려갈텐데 현실에서는 있을 수 없는일이다</li>
<li>농어의 길이와 무게에 대한 산점도를 자세히 보면 일직선이라기 보다는 왼쪽 위로 조금 구부러진 곡선에 가깝다 &#x3D; 2차방정식</li>
</ul>
<h2 id="선형-회귀"><a href="#선형-회귀" class="headerlink" title="선형 회귀"></a>선형 회귀</h2><ul>
<li>다항 회귀</li>
<li>농어 1cm &#x3D; -650g</li>
<li>직선의 기울기 대신, 곡선의 기울기를 쓰자</li>
<li>직선 &#x3D; 1차방정식, 곡선 &#x3D; 2차방정식</li>
<li>$y &#x3D; ax^2 + bx + b$</li>
<li>$무게 &#x3D; a길이^2 + b길이 + 절편$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># p140</span></span><br><span class="line">train_poly = np.column_stack((train_input ** <span class="number">2</span>, train_input)) <span class="comment">#train_input ** 2: train_input을 제곱 / column_stack():1 차원 배열을 2 차원 배열에 열로 쌓습니다.</span></span><br><span class="line">test_poly = np.column_stack((test_input **<span class="number">2</span>, test_input))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋 크기 확인</span></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; --------train poly --------&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; --------test poy --------&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 2) (14, 2)
 --------train poly --------
 --------test poy --------
</code></pre>
<ul>
<li>주목할 부분: 2차방정식의 그래프를 찾기위해 훈련세트에 제곱항을 추가했지만, 타깃값은 그대로 사용한다는 것</li>
<li>목표하는 값은 어떠한 그래프를 훈련하든지 바꿀필요가 없다 **</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이 모델에 농어의 길이의 제곱과 원래의 길이를 함께 넣어줘야 한다 **</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>**<span class="number">2</span>, <span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1573.98423528]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<ul>
<li>시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 구각별 직선을 그리기 위해 15에서 49까지 정수배열을 만든다</span></span><br><span class="line">point = np.arange(<span class="number">15</span>, <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 15에서 49까지 2차방정식 그래프를 그린다 **</span></span><br><span class="line">plt.plot(point, <span class="number">1.01</span>*point**<span class="number">2</span> - <span class="number">21.6</span>*point + <span class="number">116.05</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1574</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0701_ch03/output_31_0.png"></p>
<ul>
<li>점수확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(train_poly,train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9706807451768623
0.9775935108325122
</code></pre>
<ul>
<li>훈련세트와 테스트세트의 점수가 크게 높아졌다</li>
<li>하지만 여전치 테스트 세트의 점수가 조금 더 높다</li>
<li>과소적합이 아직 남아있다</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-01T00:00:00.000Z" title="2022. 7. 1. 오전 9:00:00">2022-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T03:28:35.875Z" title="2022. 7. 6. 오후 12:28:35">2022-07-06</time></span><span class="level-item">15 minutes read (About 2266 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/01/day0701_ch4/">로지스틱 회귀</a></h1><div class="content"><h2 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h2><ul>
<li>선형회귀에서 출발</li>
<li>이진 분류 문제 해결</li>
<li>클래스 확률 예측</li>
<li>딥러닝에서도 사용됨</li>
</ul>
<p>p177</p>
<ul>
<li>x가 사각형일 확률 30%</li>
<li>y가 삼각형일 확률 50%</li>
<li>x가 원일 확률 20%</li>
</ul>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><ul>
<li><p>Species (종속변수&#x3D;Y) -&gt; 타깃</p>
</li>
<li><p>독립변수 : Weight, Length, Diagonal, Height, Width -&gt; 입력 데이터</p>
</li>
<li><p>파이썬을 통해 데이터 분석을 할 때, Pandas를 빼놓고 이야기할 수 없다. 온전히 통계 분석을 위해 고안된 R 과는 다르게 python은 일반적인 프로그래밍 언어(general purpose programming language) 이며, 데이터 분석을 하기 위해서는 여러가지 라이브러리를 사용할 수 밖에 없다. 이 패키지들 중 R의 dataframe 데이터 타입을 참고하여 만든 것이 바로 pandas dataframe이다. pandas는 dataframe을 주로 다루기 위한 라이브러리이며, dataframe을 자유롭게 가공하는 것은 데이터 과학자들에게 중요하다. </p>
</li>
<li><p>데이터 프레임은 넘파이로 상호변환이 쉽고, 사이런킷과도 잘 호환된다</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fish = pd.read_csv(<span class="string">&#x27;https://bit.ly/fish_csv_data&#x27;</span>)</span><br><span class="line">fish.head()</span><br></pre></td></tr></table></figure>





  <div id="df-76aa0f66-ffe7-4987-a45c-016731eef719">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length</th>
      <th>Diagonal</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-76aa0f66-ffe7-4987-a45c-016731eef719')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-76aa0f66-ffe7-4987-a45c-016731eef719 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-76aa0f66-ffe7-4987-a45c-016731eef719&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<h2 id="데이터-탐색-실제작업시-시간소요"><a href="#데이터-탐색-실제작업시-시간소요" class="headerlink" title="데이터 탐색 (실제작업시 시간소요)"></a>데이터 탐색 (실제작업시 시간소요)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 종속변수</span></span><br><span class="line"><span class="built_in">print</span>(pd.unique(fish[<span class="string">&#x27;Species&#x27;</span>])) <span class="comment">#unique():데이터에 고유값들이 어떠한 종류들이 있는지 알고 싶을때 사용하는 함수</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Roach&#39; &#39;Whitefish&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Smelt&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(fish[<span class="string">&#x27;Species&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>

<pre><code>Perch        56
Bream        35
Roach        20
Pike         17
Smelt        14
Parkki       11
Whitefish     6
Name: Species, dtype: int64
</code></pre>
<h2 id="데이터-가공"><a href="#데이터-가공" class="headerlink" title="데이터 가공"></a>데이터 가공</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 입력데이터 만들기</span></span><br><span class="line"><span class="comment"># 데이터프레임에서 여러열을 선택하면 새로운 데이터 프레임이 반환되며, 이를 to_numpy()메서드로 넘파이 배열로 바꾼다</span></span><br><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>,<span class="string">&#x27;Diagonal&#x27;</span>,<span class="string">&#x27;Height&#x27;</span>,<span class="string">&#x27;Width&#x27;</span> ]].to_numpy() </span><br><span class="line">fish_input.shape</span><br></pre></td></tr></table></figure>




<pre><code>(159, 5)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(fish_input[:<span class="number">5</span>]) <span class="comment">#[:5] : 처음 5개 행</span></span><br></pre></td></tr></table></figure>

<pre><code>[[242.      25.4     30.      11.52     4.02  ]
 [290.      26.3     31.2     12.48     4.3056]
 [340.      26.5     31.1     12.3778   4.6961]
 [363.      29.      33.5     12.73     4.4555]
 [430.      29.      34.      12.444    5.134 ]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 타깃데이터 만들기</span></span><br><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy() <span class="comment"># [&#x27;Species&#x27;] : [[&#x27;Species&#x27;]]사용하지 않도록 주의, 그렇게 하면 fish_target이 2차원 배열이 됨 **</span></span><br></pre></td></tr></table></figure>

<h2 id="데이터-분리"><a href="#데이터-분리" class="headerlink" title="데이터 분리"></a>데이터 분리</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 세트 2개 만들기 </span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 층화 샘플링</span></span><br></pre></td></tr></table></figure>

<h2 id="표준화-전처리"><a href="#표준화-전처리" class="headerlink" title="표준화 전처리"></a>표준화 전처리</h2><ul>
<li>여기에서도 훈련 세트의 통계 값으로 테스트 세트를 변환해야 한다는 점을 잊지 않기 **</li>
<li>데이터 가공</li>
</ul>
<ul>
<li>숫자 결측치가 존재, 평균값으로 대체</li>
<li>원본 데이터 평균 대치 (x) &gt; 훈련 데이터로 평균대치 (o)</li>
<li>훈련 데이터와 테스트 데이터 분리</li>
</ul>
<ul>
<li>데이터 누수(Data Leakage)</li>
</ul>
<ul>
<li>훈련데이터 평균값 70을 대치 (o)</li>
<li>테스트데이터 평균값 75를 대치 (x)</li>
<li>모든 데이터 평균값 72.5를 대치 (x)</li>
</ul>
<p> 참고 사이트<br> <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/common_pitfalls.html">https://scikit-learn.org/stable/common_pitfalls.html</a> </p>
<p>참고 코드 (무조건 pipeline 으로 사용: 중간에 복잡한 내용없이 안전하게 실행가능) : Data Leakage 방지가능</p>
<p>from sklearn.pipeline import make_pipeline</p>
<p>model &#x3D; make_pipeline(StandardScaler(), LinearRegression())</p>
<p>model.fit(X_train, y_train)</p>
<p>Pipeline(steps&#x3D;[(‘standardscaler’, StandardScaler()),<br>                (‘linearregression’, LinearRegression())])</p>
<p>mean_squared_error(y_test, model.predict(X_test))<br>0.90…</p>
<ul>
<li>Pipelines also help avoiding another common pitfall: leaking the test data into the training data.</li>
</ul>
<p>교재 p97</p>
<ul>
<li>기준을 맞춰라 –&gt; 데이터 표준화(표준점수)</li>
<li>수동으로 mean, std</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># p100</span></span><br><span class="line"><span class="comment"># train_scaled = (train_input - mean)/std</span></span><br></pre></td></tr></table></figure>

<p>StandardScaler() 참고 </p>
<p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># StandardScaler 클래스 사용하여 훈련세트와 데이터세트를 표준화 전처리하기</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"><span class="comment"># ss.fit(test_input) (x)</span></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h2 id="모형-만들기"><a href="#모형-만들기" class="headerlink" title="모형 만들기"></a>모형 만들기</h2><ul>
<li>k-최근접 이웃</li>
<li>보통 1개의 모형만 만들지는 않음 &#x2F; 여러개의 샘플링</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">kn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(kn.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(kn.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8907563025210085
0.85
</code></pre>
<ul>
<li>타깃값 확인</li>
<li>알파벳 순으로 정렬</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.classes_) </span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict(test_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Perch&#39; &#39;Perch&#39;]
</code></pre>
<ul>
<li>5개 샘플에 대한 예측은 어떤 확률인가?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>]) <span class="comment">#predict_proba()메서드: 클래스별 확률값 반환 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#round()함수는 기본으로 소수점 첫째자리에서 반올림, decimals 매개변수로 유지할 소수점 아래자릿수 지정가능</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">4</span>)) </span><br></pre></td></tr></table></figure>

<pre><code>[[0.     0.     1.     0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     1.     0.     0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
</code></pre>
<ul>
<li>첫 번째 클래스 Perch<br> +100% 확률로 Perch 예측</li>
<li>네번째 클래스 Perch</li>
</ul>
<ul>
<li>66.7% 확률로 Perch로 예측</li>
<li>33.3% 확률로 Perch로 예측</li>
</ul>
<h2 id="회귀식"><a href="#회귀식" class="headerlink" title="회귀식"></a>회귀식</h2><p>y &#x3D; ax + b</p>
<ul>
<li>양변에 로그를 취함</li>
</ul>
<h2 id="로지스틱회귀"><a href="#로지스틱회귀" class="headerlink" title="로지스틱회귀"></a>로지스틱회귀</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">z = np.arange(-<span class="number">5</span>,<span class="number">5</span>,<span class="number">0.5</span>)</span><br><span class="line">phi = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z)) <span class="comment">#np.exp 지수함수계산</span></span><br><span class="line">plt.plot(z, phi)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;phi&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0701_ch04/output_30_0.png"></p>
<h2 id="로지스틱-회귀로-이진-분류-수행"><a href="#로지스틱-회귀로-이진-분류-수행" class="headerlink" title="로지스틱 회귀로 이진 분류 수행"></a>로지스틱 회귀로 이진 분류 수행</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 넘파이배열은 True, False값을 전달하여 행을 선택 </span></span><br><span class="line">char_arr = np.array([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(char_arr[[<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>]])</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;A&#39; &#39;C&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bream_smelt_indexes = (train_target == <span class="string">&#x27;Bream&#x27;</span>) | (train_target == <span class="string">&#x27;Smelt&#x27;</span>) <span class="comment"># | : OR연산자 / bream_smelt_indexes배열: 도미와 빙어일경우 True, 그외에는 모두 False</span></span><br><span class="line">train_bream_smelt = train_scaled[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt = train_target[bream_smelt_indexes]</span><br><span class="line"></span><br><span class="line">train_scaled.shape, train_bream_smelt.shape</span><br></pre></td></tr></table></figure>




<pre><code>((119, 5), (33, 5))
</code></pre>
<h2 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_bream_smelt, target_bream_smelt)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 클래스를 예측</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict(train_bream_smelt[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<ul>
<li>확률값 구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict_proba(train_bream_smelt[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39;]
</code></pre>
<ul>
<li>분류기준: threshold 임계값 설정 (경계선을 긋는)</li>
</ul>
<p>계수와 절편</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decisions = lr.decision_function(train_bream_smelt[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(decisions)</span><br></pre></td></tr></table></figure>

<pre><code>[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
</code></pre>
<ul>
<li>z값을 확률값으로 변환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="built_in">print</span>(expit(decisions))</span><br></pre></td></tr></table></figure>

<pre><code>[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre>
<h2 id="다중-분류-수행하기"><a href="#다중-분류-수행하기" class="headerlink" title="다중 분류 수행하기"></a>다중 분류 수행하기</h2><ul>
<li>이진분류의 확장판</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 하이퍼 파라미터 세팅</span></span><br><span class="line"><span class="comment"># 모형을 튜닝</span></span><br><span class="line"><span class="comment"># 모형 결과의 과대적합 또는 과소적합을 방지하기 위한 것</span></span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(C=<span class="number">20</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9327731092436975
0.925
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict(test_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Perch&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">proba = lr.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
</code></pre>
<ul>
<li>다중 분류일 경우 선형 방정식은 어떤 모습일까?</li>
<li>분류 7개, 칼럼 값 5개</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_.shape, lr.intercept_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(7, 5) (7,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decision = lr.decision_function(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(decision, decimals=<span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]
 [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]
 [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]
 [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]
 [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> softmax</span><br><span class="line">proba = softmax(decision, axis =<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
</code></pre>
<p>교재에는 관련 내용없음</p>
<h2 id="평가-지표-실제-평가시-이용"><a href="#평가-지표-실제-평가시-이용" class="headerlink" title="평가 지표 (실제 평가시 이용)"></a>평가 지표 (실제 평가시 이용)</h2><ul>
<li>회귀 평가지표</li>
<li>결정 계수 (p121)</li>
</ul>
<ul>
<li>(타깃-예측)^2의 합 &#x2F; (타깃-평균)^2의 합</li>
</ul>
<ul>
<li>MAE, MSE, RMSE</li>
</ul>
<ul>
<li>(실제 - 예측)&#x3D; 오차</li>
<li>MAE(Mean Absoluted Error) : 오차의 절댓값의 평균</li>
<li>MES(Meen Squared Error) : 오차 제곱의 평균</li>
<li>RMSE(Root Mean Squared Error):MSE에 제곱근을 취한 값</li>
</ul>
<ul>
<li>좋은 모델이란?</li>
</ul>
<ul>
<li>결정계수 : 1에 수렴하면 좋은 모델</li>
<li>MAE, MSE, RMSE : 0에 수렴하면 좋은 모델</li>
</ul>
<p>참고<br> <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">true = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>]) <span class="comment"># 실제값</span></span><br><span class="line">preds = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">8</span>]) <span class="comment"># 예측값</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#절대값 오차의 평균</span></span><br><span class="line">mae = mean_absolute_error(true, preds)</span><br><span class="line"><span class="built_in">print</span>(mae)</span><br><span class="line"></span><br><span class="line"><span class="comment">#제곱 오차의 평균</span></span><br><span class="line">mse = mean_squared_error(true, preds)</span><br><span class="line"><span class="built_in">print</span>(mse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mse제곱근</span></span><br><span class="line">rmse = np.sqrt(mse)</span><br><span class="line"><span class="built_in">print</span>(rmse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 결정계수</span></span><br><span class="line">r2 = r2_score(true, preds)</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>0.5384615384615384
0.6923076923076923
0.8320502943378437
0.8617021276595744
</code></pre>
<h2 id="분류-평가-지표"><a href="#분류-평가-지표" class="headerlink" title="분류 평가 지표"></a>분류 평가 지표</h2><ul>
<li>오차 행렬</li>
<li>실제 값</li>
</ul>
<ul>
<li>[빙어, 도미, 도미, 빙어, 도미]</li>
<li>[빙어, 빙어, 도미, 빙어, 빙어]</li>
</ul>
<p>TP(빙어를 빙어로 예측) : 2<br>TN(도미를 도미로 예측) : 1<br>FN(실제 도미, 예측 빙어) : 2<br>FP(실제 빙어, 예측 도미) : 0</p>
<ul>
<li>TP, TN, FP, FN</li>
</ul>
<ul>
<li>TP&#x3D;5, TN&#x3D;5, FP&#x3D;3, FN&#x3D;7</li>
<li>정확도 :(TP+TN)&#x2F;(TP+TN+FP+FN)</li>
<li>정밀도 : 양성이라고 예측한 값(TP+FP)중 실제 양성인 값의 비율</li>
<li>재현율 : 실제 양성인 값 중에서 양성으로 예측한 값(TP)의 비율<ul>
<li>코로나검사</li>
</ul>
<ul>
<li>양성(1) : 음성(99)</li>
<li>머신러닝 모형 : 정확도 98% &#x2F; 정밀도 99%</li>
<li>인간 음성진단 : 정확도 99% &#x2F; 정밀도 95%</li>
</ul>
</li>
</ul>
<ul>
<li>검사자가 실제는 양성, 진단은 음성으로 내림</li>
</ul>
<ul>
<li>로그손실 </li>
<li>ROC Curve (&#x3D;AUC)</li>
</ul>
<ul>
<li><p>정밀도, 재현율 : 타깃데이터가 불안정시&#x2F; 정확도 확인어려울시 </p>
</li>
<li><p>모형의 정확도 3&#x2F;5 &#x3D; 60%</p>
</li>
</ul>
<p>분류 모델 평가방법 참고 </p>
<p><a target="_blank" rel="noopener" href="https://velog.io/@skyepodium/%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95">https://velog.io/@skyepodium/%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">true = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">pred = [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">confusion_matrix(true, pred)</span><br></pre></td></tr></table></figure>




<pre><code>array([[2, 1],
       [2, 0]])
</code></pre>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">25</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-14T00:00:00.000Z">2022-07-14</time></p><p class="title"><a href="/2022/07/14/0220714/">seborn 라이브러리</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-07T00:00:00.000Z">2022-07-07</time></p><p class="title"><a href="/2022/07/07/lecture-in-humanedu/">캐글입문</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-06T11:39:54.239Z">2022-07-06</time></p><p class="title"><a href="/2022/07/06/day0706_1200/">XGboost &amp; LightGBM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-06T03:00:00.000Z">2022-07-06</time></p><p class="title"><a href="/2022/07/06/test/">test from labtop</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-06T00:00:00.000Z">2022-07-06</time></p><p class="title"><a href="/2022/07/06/day0706_seborn/">seaborn</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="내 블로그" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>